{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqXGnjPGDwD-"
      },
      "source": [
        "# Importing useful libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddINKLWD9Ag0",
        "outputId": "202da39b-01be-4407-ea5e-c8aeae3b62c4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5enPHNVDzk0"
      },
      "source": [
        "# Setting up folder paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waVC_xTbC8tT"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/m10/projeto/data'\n",
        "\n",
        "tif_images_path = f'{data_path}/tci_tifs/'\n",
        "masks_images_path = f'{data_path}/masks/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDNDFI9VDur1"
      },
      "source": [
        "# Loading TIF images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZTcCiJ3g8wy"
      },
      "outputs": [],
      "source": [
        "# Carregando os arquivos\n",
        "tif_images_files = os.listdir(tif_images_path)\n",
        "masks_images_files = os.listdir(masks_images_path)\n",
        "\n",
        "# Listas para armazenar imagens, máscaras e metadados\n",
        "images_metadatas = []\n",
        "images_arrays = []\n",
        "masks_images = []\n",
        "masks_metadatas = []\n",
        "\n",
        "# Carregar imagens TIFF\n",
        "for file in tif_images_files:\n",
        "    if file.endswith('.tif'):\n",
        "        full_path = os.path.join(tif_images_path, file)\n",
        "        image = cv2.imread(full_path)\n",
        "        if image is not None:\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image_id = file.split('_')[0]  # Assume que o ID está na primeira parte do nome do arquivo\n",
        "\n",
        "            image_metadata = {\n",
        "                \"id\": image_id,\n",
        "                \"file_name\": file,\n",
        "                \"array\": image_rgb\n",
        "            }\n",
        "\n",
        "            images_metadatas.append(image_metadata)\n",
        "\n",
        "# Carregar imagens de máscaras\n",
        "for file in masks_images_files:\n",
        "    if file.endswith('.png'):\n",
        "        full_path = os.path.join(masks_images_path, file)\n",
        "        image = cv2.imread(full_path)\n",
        "        if image is not None:\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            mask_id = file.split('.')[0]  # Assume que o ID é o nome do arquivo sem a extensão\n",
        "\n",
        "            mask_metadata = {\n",
        "                \"id\": mask_id,\n",
        "                \"file_name\": file,\n",
        "                \"array\": image_rgb\n",
        "            }\n",
        "\n",
        "            masks_metadatas.append(mask_metadata)\n",
        "\n",
        "images_metadatas = sorted(images_metadatas, key=lambda x: x['id'])\n",
        "masks_metadatas = sorted(masks_metadatas, key=lambda x: x['id'])\n",
        "\n",
        "images_arrays = [metadata['array'] for metadata in images_metadatas]\n",
        "masks_images = [metadata['array'] for metadata in masks_metadatas]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16xySalcFf-m"
      },
      "source": [
        "# Visualizing Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkVn2zv3Q77R"
      },
      "outputs": [],
      "source": [
        "def plot_images(images_arrays, images_metadatas=None, num_columns=5, figsize=(15, 3)):\n",
        "    \"\"\"\n",
        "    Plots images with their metadata as titles in a grid layout.\n",
        "\n",
        "    Parameters:\n",
        "        images_arrays (list): List of image arrays.\n",
        "        images_metadatas (list, optional): List of dictionaries containing image metadata. Defaults to None.\n",
        "        num_columns (int, optional): Number of columns in the grid layout. Defaults to 5.\n",
        "        figsize (tuple, optional): Figure size. Defaults to (15, 3).\n",
        "    \"\"\"\n",
        "    num_images = len(images_arrays)\n",
        "    num_rows = (num_images + num_columns - 1) // num_columns\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(figsize[0], figsize[1] * num_rows))\n",
        "    fig.tight_layout(pad=3.0)\n",
        "\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for idx in range(num_images):\n",
        "        ax = axes[idx]\n",
        "        ax.imshow(images_arrays[idx])\n",
        "        if images_metadatas is not None and 'file_name' in images_metadatas[idx]['metadata']:\n",
        "            ax.set_title(f\"{images_metadatas[idx]['metadata']['file_name']}\\nShape {images_arrays[idx].shape}\", fontsize=10)\n",
        "        else:\n",
        "            ax.set_title(f\"Image {idx}\\nShape {images_arrays[idx].shape}\", fontsize=10)\n",
        "        ax.grid(False)\n",
        "        ax.axis('on')\n",
        "\n",
        "    for ax in axes[num_images:]:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "sp74fm_-Q9w6",
        "outputId": "c51fc261-9d55-4139-bb2b-8493d67a9a74"
      },
      "outputs": [],
      "source": [
        "plot_images(images_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "MAOZ2EC4gnIG",
        "outputId": "4857fc52-61aa-4830-9506-335f09ebd820"
      },
      "outputs": [],
      "source": [
        "plot_images(masks_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsAS-2BbHRMu"
      },
      "source": [
        "# Check if all images are the same shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laFlySnell-V"
      },
      "outputs": [],
      "source": [
        "def check_invalid_image_shapes(images_arrays, target_shape=(1200, 1200, 3), images_metadatas=None):\n",
        "    \"\"\"\n",
        "    Checks each image array in the provided list for a specific shape and prints filenames or indices of those that do not match.\n",
        "\n",
        "    Parameters:\n",
        "        images_arrays (list): List of image arrays.\n",
        "        target_shape (tuple): The expected shape of the images (height, width, channels).\n",
        "        images_metadatas (list, optional): List of dictionaries containing image metadata. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if all images match the target shape, False otherwise.\n",
        "    \"\"\"\n",
        "    all_valid = True  # Assume all images are valid until proven otherwise\n",
        "    for idx, image_array in enumerate(images_arrays):\n",
        "        if image_array.shape != target_shape:\n",
        "            if images_metadatas and idx < len(images_metadatas) and 'file_name' in images_metadatas[idx].get('metadata', {}):\n",
        "                print(f\"Image {images_metadatas[idx]['metadata']['file_name']} has incorrect shape {image_array.shape}\")\n",
        "            else:\n",
        "                print(f\"Image {idx} has incorrect shape {image_array.shape}\")\n",
        "            all_valid = False\n",
        "    return all_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2UXDxfbMkuS",
        "outputId": "7ab0ef2a-0df5-42b5-d3f8-a5b981ab5987"
      },
      "outputs": [],
      "source": [
        "all_valid = check_invalid_image_shapes(images_arrays=images_arrays,\n",
        "                                       target_shape=(1200, 1200, 3))\n",
        "\n",
        "if all_valid:\n",
        "    print(\"All images have the correct shape.\")\n",
        "else:\n",
        "    print(\"Some images do not match the expected shape.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQNv7Q9rgdVX"
      },
      "source": [
        "# Crop images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O0p50_pgeut"
      },
      "outputs": [],
      "source": [
        "def crop_randomly(img, mask, n, new_width, new_height):\n",
        "    \"\"\"\n",
        "    Randomly crops the given image and mask arrays into 'n' new images and masks with dimensions 'new_width' x 'new_height'.\n",
        "\n",
        "    Parameters:\n",
        "        img (numpy.ndarray): The numpy array representing the original image.\n",
        "        mask (numpy.ndarray): The numpy array representing the original mask.\n",
        "        n (int): The number of new images and masks to generate.\n",
        "        new_width (int): The width of the new images and masks.\n",
        "        new_height (int): The height of the new images and masks.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing three elements:\n",
        "               - A list of numpy.ndarray representing the cropped images.\n",
        "               - A list of numpy.ndarray representing the cropped masks.\n",
        "               - A list of tuples containing the top-left corner coordinates of each cropped area.\n",
        "    \"\"\"\n",
        "    original_height, original_width, _ = img.shape\n",
        "    cropped_images = []\n",
        "    cropped_masks = []\n",
        "    crop_coordinates = []\n",
        "\n",
        "    if new_width > original_width or new_height > original_height:\n",
        "        raise ValueError(\"New dimensions must be smaller than or equal to the original dimensions.\")\n",
        "\n",
        "    for _ in range(n):\n",
        "        # Randomly select top-left corner coordinates for cropping\n",
        "        top = np.random.randint(0, original_height - new_height + 1)\n",
        "        left = np.random.randint(0, original_width - new_width + 1)\n",
        "\n",
        "        # Crop the image and mask using the same coordinates\n",
        "        cropped_image = img[top:top + new_height, left:left + new_width, :]\n",
        "        cropped_mask = mask[top:top + new_height, left:left + new_width]\n",
        "\n",
        "        # Store the cropped image, mask, and coordinates\n",
        "        cropped_images.append(cropped_image)\n",
        "        cropped_masks.append(cropped_mask)\n",
        "        crop_coordinates.append((left, top))\n",
        "\n",
        "    return cropped_images, cropped_masks, crop_coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSXKYbaLUUHB"
      },
      "source": [
        "# Visualizing cropped images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FisNOyjqUjUG"
      },
      "outputs": [],
      "source": [
        "def draw_rectangles_on_image(original_image, cropped_images, crop_coordinates):\n",
        "    \"\"\"\n",
        "    Draws rectangles representing crop areas on the original image.\n",
        "\n",
        "    Parameters:\n",
        "        original_image (numpy.ndarray): The numpy array representing the original image.\n",
        "        cropped_images (list): List of numpy.ndarray representing the cropped images.\n",
        "        crop_coordinates (list): List of tuples containing the top-left corner coordinates of each cropped image.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The original image with rectangles drawn on it.\n",
        "    \"\"\"\n",
        "    output_image = original_image.copy()\n",
        "\n",
        "    for crop_coord in crop_coordinates:\n",
        "        x, y = crop_coord\n",
        "        cv2.rectangle(output_image, (x, y), (x + cropped_images[0].shape[1], y + cropped_images[0].shape[0]), (0, 255, 0), 2)\n",
        "\n",
        "    return output_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZyHoocIllL7"
      },
      "outputs": [],
      "source": [
        "cropped_images, cropped_masks, crop_coordinates = crop_randomly(images_arrays[0], masks_images[0], 5, 120, 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "0bz2EdcxSrSy",
        "outputId": "8a4fe382-53ce-43ff-f120-155198c8ea56"
      },
      "outputs": [],
      "source": [
        "plt.imshow(images_arrays[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "FadRd3lYR_Zb",
        "outputId": "3e28ec52-59a5-45d4-ee3f-97d75797326e"
      },
      "outputs": [],
      "source": [
        "plot_images(cropped_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "adXnzOZViWf6",
        "outputId": "f5e93402-38a3-4436-928b-7349195b102a"
      },
      "outputs": [],
      "source": [
        "plot_images(cropped_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "gzobrthTUXjb",
        "outputId": "f9411d84-10e8-48ca-e71b-220f3cc16bde"
      },
      "outputs": [],
      "source": [
        "plt.imshow(draw_rectangles_on_image(images_arrays[0], cropped_images, crop_coordinates))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spSOO0R8UwfP"
      },
      "source": [
        "# Data Augmentation - Old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA6tTZe-Yx4f"
      },
      "outputs": [],
      "source": [
        "def data_augmentation(image, num_augmentations=3):\n",
        "    \"\"\"\n",
        "    Applies data augmentation to a single image.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The numpy array representing the original image.\n",
        "        num_augmentations (int, optional): Number of augmentations to apply to the image. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        list: List of numpy.ndarray representing the augmented images.\n",
        "    \"\"\"\n",
        "    augmented_images = []\n",
        "    previous_transformations = set()\n",
        "\n",
        "    while len(augmented_images) < num_augmentations:\n",
        "        # Randomly choose augmentation type\n",
        "        augmentation_type = random.choice(['rotate', 'translate', 'flip', 'brightness_contrast'])\n",
        "\n",
        "        # Generate random transformation parameters\n",
        "        if augmentation_type == 'rotate':\n",
        "            angle = random.choice([-15, -10, -5, 5, 10, 15])  # Rotation angles in degrees\n",
        "            transformation_key = ('rotate', angle)\n",
        "        elif augmentation_type == 'translate':\n",
        "            translation = random.choice([(15, 15), (-15, -15), (15, -15), (-15, 15), (10, 10), (-10, -10), (10, -10), (-10, 10)])  # Translations in (dx, dy) format\n",
        "            transformation_key = ('translate', translation)\n",
        "        elif augmentation_type == 'flip':\n",
        "            flip_type = random.choice([-1, 0, 1])  # Flip horizontally, vertically, or both\n",
        "            transformation_key = ('flip', flip_type)\n",
        "        elif augmentation_type == 'brightness_contrast':\n",
        "            alpha = random.uniform(0.3, 3.0)  # Randomly choose alpha (contrast)\n",
        "            beta = random.randint(-100, 100)  # Randomly choose beta (brightness)\n",
        "            transformation_key = ('brightness_contrast', alpha, beta)\n",
        "\n",
        "        # Check if the generated transformation has already been applied\n",
        "        if transformation_key in previous_transformations:\n",
        "            continue  # Skip if transformation already applied\n",
        "\n",
        "        # Apply the transformation and store the image\n",
        "        if augmentation_type == 'rotate':\n",
        "            augmented_image = rotate_image(image, angle)\n",
        "        elif augmentation_type == 'translate':\n",
        "            augmented_image = translate_image(image, translation)\n",
        "        elif augmentation_type == 'flip':\n",
        "            augmented_image = flip_image(image, flip_type)\n",
        "        elif augmentation_type == 'brightness_contrast':\n",
        "            augmented_image = adjust_brightness_contrast(image, alpha, beta)\n",
        "\n",
        "        augmented_images.append(augmented_image)\n",
        "        previous_transformations.add(transformation_key)\n",
        "\n",
        "    return augmented_images\n",
        "\n",
        "def rotate_image(image, angle):\n",
        "    \"\"\"\n",
        "    Rotates the given image by the specified angle.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The numpy array representing the image.\n",
        "        angle (int): The rotation angle in degrees.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The rotated image.\n",
        "    \"\"\"\n",
        "    height, width = image.shape[:2]\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
        "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
        "    return rotated_image\n",
        "\n",
        "def translate_image(image, translation):\n",
        "    \"\"\"\n",
        "    Translates the given image by the specified translation (dx, dy).\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The numpy array representing the image.\n",
        "        translation (tuple): The translation in (dx, dy) format.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The translated image.\n",
        "    \"\"\"\n",
        "    height, width = image.shape[:2]\n",
        "    translation_matrix = np.float32([[1, 0, translation[0]], [0, 1, translation[1]]])\n",
        "    translated_image = cv2.warpAffine(image, translation_matrix, (width, height))\n",
        "    return translated_image\n",
        "\n",
        "def apply_random_filter(image):\n",
        "    \"\"\"\n",
        "    Applies a random filter to the given image.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The numpy array representing the image.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The image with the applied filter.\n",
        "    \"\"\"\n",
        "    filters = [cv2.GaussianBlur, cv2.medianBlur, cv2.bilateralFilter]\n",
        "    selected_filter = random.choice(filters)\n",
        "    if selected_filter == cv2.GaussianBlur or selected_filter == cv2.medianBlur:\n",
        "        filtered_image = selected_filter(image, (5, 5))  # Kernel size: 5x5\n",
        "    else:  # selected_filter == cv2.bilateralFilter\n",
        "        filtered_image = selected_filter(image, 9, 75, 75)  # d: Diameter of pixel neighborhood, sigmaColor: Filter sigma in the color space, sigmaSpace: Filter sigma in the coordinate space\n",
        "    return filtered_image\n",
        "\n",
        "def apply_random_blur(image):\n",
        "    \"\"\"\n",
        "    Applies random blur to the given image.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The numpy array representing the image.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The image with the applied blur.\n",
        "    \"\"\"\n",
        "    blur_types = ['gaussian', 'median', 'bilateral']\n",
        "    selected_blur_type = random.choice(blur_types)\n",
        "    if selected_blur_type == 'gaussian':\n",
        "        blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "    elif selected_blur_type == 'median':\n",
        "        blurred_image = cv2.medianBlur(image, 5)\n",
        "    elif selected_blur_type == 'bilateral':\n",
        "        blurred_image = cv2.bilateralFilter(image, 9, 75, 75)\n",
        "    return blurred_image\n",
        "\n",
        "def flip_image(image, flip_type):\n",
        "  \"\"\"\n",
        "  Applies flip transformation to the given image.\n",
        "\n",
        "  Parameters:\n",
        "      image (numpy.ndarray): The numpy array representing the image.\n",
        "      flip_type (int): Type of flip transformation.\n",
        "                        0: Flip vertically\n",
        "                        1: Flip horizontally\n",
        "                        -1: Flip both vertically and horizontally\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: The image with the applied flip transformation.\n",
        "  \"\"\"\n",
        "  return cv2.flip(image, flip_type)\n",
        "\n",
        "def adjust_brightness_contrast(image, alpha, beta):\n",
        "    \"\"\"\n",
        "    Applies brightness and contrast adjustment to the given image.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): The numpy array representing the image.\n",
        "        alpha (float): Alpha value for contrast adjustment.\n",
        "        beta (int): Beta value for brightness adjustment.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The image with the applied brightness and contrast adjustment.\n",
        "    \"\"\"\n",
        "    adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "    return adjusted_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqj-9Yvf9RVu"
      },
      "outputs": [],
      "source": [
        "augmented_images = data_augmentation(cropped_images[0], 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R518x8A1BgQf"
      },
      "outputs": [],
      "source": [
        "plt.imshow(cropped_images[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oswbtJUu90OS",
        "outputId": "344abf61-a894-48eb-fdc2-e17a2abc6a3c"
      },
      "outputs": [],
      "source": [
        "plot_images(augmented_images, num_columns=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imL7yZUSBaDG"
      },
      "source": [
        "# Data Augmentation Adjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCiuDIOVlwpB"
      },
      "outputs": [],
      "source": [
        "class BaseImageProcess:\n",
        "    \"\"\"\n",
        "    BaseImageProcess: A base class for image processing algorithms.\n",
        "\n",
        "    This class provides a basic framework for implementing image processing algorithms and is intended to be subclassed.\n",
        "    Subclasses should implement the `apply` method to perform specific image processing operations on an input image.\n",
        "    \"\"\"\n",
        "    def apply(self, img):\n",
        "        \"\"\"\n",
        "        Placeholder for applying an image processing algorithm.\n",
        "\n",
        "        Args:\n",
        "            img: The input image to process.\n",
        "\n",
        "        Returns:\n",
        "            The processed image.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "class Rotate(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.angle = random.choice([-15, -10, -5, 5, 10, 15])\n",
        "\n",
        "    def apply(self, img):\n",
        "        height, width = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), self.angle, 1)\n",
        "        return cv2.warpAffine(img, rotation_matrix, (width, height))\n",
        "\n",
        "class Translate(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.dx = random.choice([-10, -5, 0, 5, 10])\n",
        "        self.dy = random.choice([-10, -5, 0, 5, 10])\n",
        "\n",
        "    def apply(self, img):\n",
        "        translation_matrix = np.float32([[1, 0, self.dx], [0, 1, self.dy]])\n",
        "        height, width = img.shape[:2]\n",
        "        return cv2.warpAffine(img, translation_matrix, (width, height))\n",
        "\n",
        "class Flip(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.flip_type = random.choice([-1, 0, 1])\n",
        "\n",
        "    def apply(self, img):\n",
        "        return cv2.flip(img, self.flip_type)\n",
        "\n",
        "class BrightnessContrast(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.alpha = random.uniform(0.5, 1.5)\n",
        "        self.beta = random.randint(-50, 50)\n",
        "\n",
        "    def apply(self, img):\n",
        "        return cv2.convertScaleAbs(img, alpha=self.alpha, beta=self.beta)\n",
        "\n",
        "class GaussianBlur(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.kernel_size = random.choice([3, 5, 7, 9, 11])\n",
        "\n",
        "    def apply(self, img):\n",
        "        return cv2.GaussianBlur(img, (self.kernel_size, self.kernel_size), 0)\n",
        "\n",
        "class MedianBlur(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.kernel_size = random.choice([3, 5, 7, 9, 11])\n",
        "\n",
        "    def apply(self, img):\n",
        "        return cv2.medianBlur(img, self.kernel_size)\n",
        "\n",
        "class BilateralFilter(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.d = random.choice([5, 9, 15])\n",
        "        self.sigmaColor = random.choice([50, 75, 100])  # Filter sigma in the color space\n",
        "        self.sigmaSpace = random.choice([50, 75, 100])  # Filter sigma in the coordinate space\n",
        "\n",
        "    def apply(self, img):\n",
        "        return cv2.bilateralFilter(img, self.d, self.sigmaColor, self.sigmaSpace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNI0rdvJmGPX"
      },
      "outputs": [],
      "source": [
        "def data_augmentation(images, masks, n=3, filters=None):\n",
        "    \"\"\"\n",
        "    Applies data augmentation to a list of images and their corresponding masks.\n",
        "\n",
        "    Parameters:\n",
        "        images (list of numpy.ndarray): The list of numpy arrays representing the original images.\n",
        "        masks (list of numpy.ndarray): The list of numpy arrays representing the masks for the images.\n",
        "        n (int): Number of augmentations to apply to each image.\n",
        "        filters (list): List of instantiated filter classes to apply.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two elements:\n",
        "               - List of numpy.ndarray representing the original and augmented images.\n",
        "               - List of numpy.ndarray representing the original and augmented masks.\n",
        "    \"\"\"\n",
        "    all_images = []\n",
        "    all_masks = []\n",
        "\n",
        "    for image, mask in zip(images, masks):\n",
        "        augmented_images = [image]  # Include the original image\n",
        "        augmented_masks = [mask]    # Include the original mask\n",
        "        previous_transformations = set()\n",
        "\n",
        "        while len(augmented_images) - 1 < n:\n",
        "            selected_filter = random.choice(filters)\n",
        "            # Generate a unique key for the current state of the filter to avoid applying the same filter configuration twice\n",
        "            transformation_key = (type(selected_filter).__name__, tuple(selected_filter.__dict__.values()))\n",
        "\n",
        "            if transformation_key not in previous_transformations:\n",
        "                augmented_image = selected_filter.apply(image)\n",
        "                # Apply the filter to the mask if it's a geometric transformation\n",
        "                if isinstance(selected_filter, (Rotate, Translate, Flip)):\n",
        "                    augmented_mask = selected_filter.apply(mask)\n",
        "                else:\n",
        "                    augmented_mask = mask  # Non-geometric transformations do not modify the mask\n",
        "\n",
        "                augmented_images.append(augmented_image)\n",
        "                augmented_masks.append(augmented_mask)\n",
        "                previous_transformations.add(transformation_key)\n",
        "\n",
        "        all_images.extend(augmented_images)\n",
        "        all_masks.extend(augmented_masks)\n",
        "\n",
        "    return all_images, all_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ZEnHfKmIYd"
      },
      "outputs": [],
      "source": [
        "filters = [\n",
        "    Rotate(),  # Cada chamada cria uma nova instância com um ângulo aleatório\n",
        "    Translate(),\n",
        "    Flip(),\n",
        "    BrightnessContrast(),\n",
        "    GaussianBlur(),\n",
        "    MedianBlur(),\n",
        "    BilateralFilter()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrPvBjP4nEVD"
      },
      "outputs": [],
      "source": [
        "augmented_images, augmented_masks = data_augmentation(cropped_images[:2], cropped_masks[:2], n=4, filters=filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KV0EDS6oDeC",
        "outputId": "01acf040-12e1-4da2-8a05-7673d69193d9"
      },
      "outputs": [],
      "source": [
        "len(augmented_images), len(augmented_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "PMAyQP6CnHVw",
        "outputId": "dc73f94c-5cf0-49b5-d501-bc2ebd49f469"
      },
      "outputs": [],
      "source": [
        "plot_images(augmented_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "vCB8KwshqlMs",
        "outputId": "d03e9627-dbdf-47e9-fbb4-9bbc174e36b4"
      },
      "outputs": [],
      "source": [
        "plot_images(augmented_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7iS7jGfnNeT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
