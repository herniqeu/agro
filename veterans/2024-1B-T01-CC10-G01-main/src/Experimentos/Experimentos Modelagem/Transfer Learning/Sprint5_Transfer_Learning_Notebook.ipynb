{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt0_mmIfgEc_"
      },
      "source": [
        "# Refinamento de Modelo CNN Pré-treinado\n",
        "\n",
        "Este notebook foi desenvolvido para ser rodado em um ambiente Colab. Para testes de funcionalidade, sugerimos visitar [o notebook do Colab na pasta específica com as importações já feitas](https://drive.google.com/file/d/1qpPVi71bdkMrQP3Y-sWArya48-gcdZl0/view?usp=sharing).\n",
        "\n",
        "O código foi feito para rodar em um Colab, mas utiliza o código escrito em [process.py](https://github.com/Inteli-College/2024-1B-T01-CC10-G01/blob/main/src/ProcessingPipeline/image_process/processes.py) e [pipeline.py](https://github.com/Inteli-College/2024-1B-T01-CC10-G01/blob/main/src/ProcessingPipeline/image_process/pipeline.py), ambos localizados no repositório do GitHub.\n",
        "\n",
        "Para maior facilidade de importação, também estão disponíveis [nesta pasta do Google Drive](https://drive.google.com/drive/folders/1kwaFtcbv3C8RnB4BorXmu-2_XVH42i5L?usp=sharing).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqFdD-yPkPTg"
      },
      "source": [
        "## Importações e instalações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4NBQxwka2Jq",
        "outputId": "dc7bf3c4-6e60-4dd3-eefd-ed239472a34e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import psutil\n",
        "import random\n",
        "import cv2 as cv\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, Input, BatchNormalization, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ulzXgBrjw9X",
        "outputId": "18f0ebd2-8ff6-4270-dae3-2cadfe16a752"
      },
      "outputs": [],
      "source": [
        "# Instalação necessária para importação dos módulos process.py e pipeline.py\n",
        "!pip install PyQt5 --quiet\n",
        "import PyQt5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLVJRHXOjnXH"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/grupo1/Images/notebooks') # Troque esse caminho para importação dos módulos process.py e pipeline.py\n",
        "\n",
        "import test_import as TestImport\n",
        "import pipeline as Pipeline\n",
        "import processes as Processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUFcDw1fjAG3",
        "outputId": "e984acf9-3fb4-4066-e053-e1b65ceed3c9"
      },
      "outputs": [],
      "source": [
        "TestImport.TestImportPrint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYTGyM_mlG5q"
      },
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_Y-L35Pr8IO"
      },
      "outputs": [],
      "source": [
        "def warmup_lr(epoch, lr):\n",
        "  if epoch in [20, 40]:\n",
        "    return lr/10\n",
        "\n",
        "  return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nI5NqIZxOaK"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Union, List\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def get_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray,\n",
        "        n_categories: int) -> np.ndarray:\n",
        "    '''\n",
        "    Gets confusion matrix from predictions.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true: true labels with shape (n_examples, ).\n",
        "    - y_pred: predicted labels with shape (n_examples, ).\n",
        "    - n_categories: the number of categories.\n",
        "\n",
        "    Returns:\n",
        "    n_categories x n_categories ndarray representing confusion matrix.\n",
        "    '''\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    assert y_true.ndim == 1\n",
        "\n",
        "    mtx = np.zeros(shape=(n_categories, n_categories), dtype='uint64')\n",
        "\n",
        "    for i in range(n_categories):\n",
        "        category_i = (y_true == i)\n",
        "        for j in range(n_categories):\n",
        "            category_j = (y_pred == j)\n",
        "            mtx[i, j] = (category_i & category_j).sum()\n",
        "\n",
        "    return mtx\n",
        "\n",
        "\n",
        "def get_binary_confusion_matrix(\n",
        "        y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
        "    '''\n",
        "    Gets binary confusion matrix from hard predictions.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true: Ground-truth with shape (n_examples, ).\n",
        "      Assumes 1 is for positive and 0 for negative.\n",
        "    - y_pred: Predictions with shape (n_examples, ).\n",
        "      Assumes 1 is for positive and 0 for negative.\n",
        "\n",
        "    Returns:\n",
        "    2x2 binary confusion matrix (using index 0 for positive category).\n",
        "    '''\n",
        "    y_true = y_true.astype('uint8')\n",
        "    y_pred = y_pred.astype('uint8')\n",
        "    weights = np.ones(shape=y_true.shape, dtype='float32')\n",
        "\n",
        "    tp = int(((y_true & y_pred)*weights).sum())\n",
        "    tn = int((((y_true^1) & (y_pred^1))*weights).sum())\n",
        "    fp = int((((y_true^1) & y_pred)*weights).sum())\n",
        "    fn = int(((y_true & (y_pred^1))*weights).sum())\n",
        "\n",
        "    return np.array([[tp, fn], [fp, tn]], dtype='uint64')\n",
        "\n",
        "\n",
        "def extract_binary_confusion_matrix(\n",
        "        conf_mtx: np.ndarray, category: int) -> np.ndarray:\n",
        "    '''\n",
        "    From (possibly) multi-class confusion matrix, and\n",
        "    index of positive category, computes binary\n",
        "    confusion matrix (using index 0 for positive category).\n",
        "\n",
        "    Parameters:\n",
        "    - conf_mtx: square ndarray representing the confusion matrix.\n",
        "    - category: index of category to be considered positive category.\n",
        "\n",
        "    Returns:\n",
        "    2x2 binary confusion matrix (using index 0 for positive category).\n",
        "    '''\n",
        "    assert category < conf_mtx.shape[0]\n",
        "    summ_col = conf_mtx[:, category].sum()\n",
        "    summ_row = conf_mtx[category].sum()\n",
        "    summ = conf_mtx.sum()\n",
        "    tp = conf_mtx[category, category]\n",
        "    tn = summ - (summ_col + summ_row - tp)\n",
        "    fp = summ_col - tp\n",
        "    fn = summ_row - tp\n",
        "    return np.array([\n",
        "        [tp, fn],\n",
        "        [fp, tn]], dtype='uint64')\n",
        "\n",
        "\n",
        "class ClassificationMetrics:\n",
        "    '''\n",
        "    Metrics for multi-class predictor classification.\n",
        "    '''\n",
        "\n",
        "    @classmethod\n",
        "    def from_decisions(cls, y_true: np.ndarray, y_pred: np.ndarray,\n",
        "            n_categories: int) -> 'ClassificationMetrics':\n",
        "        '''\n",
        "        Instantiates object from hard predictions.\n",
        "        '''\n",
        "        mtx = get_confusion_matrix(y_true, y_pred, n_categories=n_categories)\n",
        "        return cls(mtx)\n",
        "\n",
        "    @classmethod\n",
        "    def from_confusion_matrix(cls, conf_mtx: np.ndarray) \\\n",
        "            -> 'ClassificationMetrics':\n",
        "        '''\n",
        "        Instantiates object from confusion matrix.\n",
        "        '''\n",
        "        return cls(np.array(conf_mtx))\n",
        "\n",
        "    def __init__(self, conf_mtx: np.ndarray):\n",
        "        self._conf_mtx = conf_mtx\n",
        "        self._n_categories = conf_mtx.shape[0]\n",
        "\n",
        "    @property\n",
        "    def conf_mtx(self) -> np.ndarray:\n",
        "        '''\n",
        "        The confusion matrix of the evaluation.\n",
        "        '''\n",
        "        return self._conf_mtx\n",
        "\n",
        "    @property\n",
        "    def n_categories(self) -> int:\n",
        "        '''\n",
        "        The number of categories of the evaluated classifiers.\n",
        "        '''\n",
        "        return self._n_categories\n",
        "\n",
        "    @property\n",
        "    def accuracy(self) -> float:\n",
        "        '''\n",
        "        The accuracy of the classifier.\n",
        "        '''\n",
        "        summ = self._conf_mtx.sum()\n",
        "        return 0. if summ == 0 else float(self._conf_mtx.diagonal().sum()/summ)\n",
        "\n",
        "    def as_json_dict(self) -> Dict[str, Union[int, float]]:\n",
        "        '''\n",
        "        The metrics of the classifiers as a jsonifiable dictionary.\n",
        "        '''\n",
        "        data = {\n",
        "            'accuracy': self.accuracy,\n",
        "        }\n",
        "        return data\n",
        "\n",
        "    def for_category(self, category: int) -> 'BinaryClassificationMetrics':\n",
        "        '''\n",
        "        Gets a BinaryClassificationMetrics instance for chosen category.\n",
        "        '''\n",
        "        if category >= self._n_categories:\n",
        "            raise ValueError(\n",
        "                f'there are only {self._n_categories} classes (<= {category})')\n",
        "        return BinaryClassificationMetrics(\n",
        "            extract_binary_confusion_matrix(self._conf_mtx, category))\n",
        "\n",
        "    def split(self) -> List['BinaryClassificationMetrics']:\n",
        "        '''\n",
        "        Splits the evaluation into n_categories BinaryClassificationMetrics\n",
        "        objects.\n",
        "        '''\n",
        "        return [self.for_category(i) for i in range(self.n_categories)]\n",
        "\n",
        "\n",
        "class BinaryClassificationMetrics(ClassificationMetrics):\n",
        "    '''\n",
        "    Metrics for binary predictor classification.\n",
        "    '''\n",
        "\n",
        "    # pylint: disable=arguments-differ\n",
        "    @classmethod\n",
        "    def from_decisions(cls, y_true: np.ndarray, y_pred: np.ndarray) \\\n",
        "            -> 'BinaryClassificationMetrics':\n",
        "        '''\n",
        "        Initializes class from true and predicted hard labels.\n",
        "\n",
        "        Parameters:\n",
        "        - y_true: Ground-truth with shape (n_examples, ).\n",
        "          Assumes 1 is for positive and 0 for negative.\n",
        "        - y_pred: Predictions with shape (n_examples, ).\n",
        "          Assumes 1 is for positive and 0 for negative.\n",
        "        '''\n",
        "        assert y_true.ndim == 1\n",
        "        assert y_pred.ndim == 1\n",
        "        return BinaryClassificationMetrics(\n",
        "            get_binary_confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    def __init__(self, conf_mtx: np.ndarray):\n",
        "        super().__init__(conf_mtx)\n",
        "        assert self._n_categories == 2\n",
        "\n",
        "    @property\n",
        "    def tp(self) -> int:\n",
        "        '''\n",
        "        Number of positives classified as positives.\n",
        "        '''\n",
        "        return int(self._conf_mtx[0, 0])\n",
        "\n",
        "    @property\n",
        "    def tn(self) -> int:\n",
        "        '''\n",
        "        Number of negatives classified as negatives.\n",
        "        '''\n",
        "        return int(self._conf_mtx[1, 1])\n",
        "\n",
        "    @property\n",
        "    def fp(self) -> int:\n",
        "        '''\n",
        "        Number of negatives classified as positives.\n",
        "        '''\n",
        "        return int(self._conf_mtx[1, 0])\n",
        "\n",
        "    @property\n",
        "    def fn(self) -> int:\n",
        "        '''\n",
        "        Number of positives classified as negatives.\n",
        "        '''\n",
        "        return int(self._conf_mtx[0, 1])\n",
        "\n",
        "    @property\n",
        "    def n_pos(self) -> int:\n",
        "        '''\n",
        "        Number of positives.\n",
        "        '''\n",
        "        return self.tp + self.fn\n",
        "\n",
        "    @property\n",
        "    def n_neg(self) -> int:\n",
        "        '''\n",
        "        Number of negatives.\n",
        "        '''\n",
        "        return self.tn + self.fp\n",
        "\n",
        "    @property\n",
        "    def tpr(self) -> float:\n",
        "        '''\n",
        "        True positive rate.\n",
        "        '''\n",
        "        return 0. if self.n_pos < 1 else self.tp/self.n_pos\n",
        "\n",
        "    @property\n",
        "    def tnr(self) -> float:\n",
        "        '''\n",
        "        True negative rate.\n",
        "        '''\n",
        "        return 0. if self.n_neg < 1 else self.tn/self.n_neg\n",
        "\n",
        "    @property\n",
        "    def fpr(self) -> float:\n",
        "        '''\n",
        "        False positive rate.\n",
        "        '''\n",
        "        return 1 - self.tnr\n",
        "\n",
        "    @property\n",
        "    def fnr(self) -> float:\n",
        "        '''\n",
        "        False negative rate.\n",
        "        '''\n",
        "        return 1 - self.tpr\n",
        "\n",
        "    @property\n",
        "    def precision(self) -> float:\n",
        "        '''\n",
        "        Precision.\n",
        "        '''\n",
        "        return 0. if (self.tp + self.fp < 1) else self.tp/(self.tp + self.fp)\n",
        "\n",
        "    @property\n",
        "    def recall(self) -> float:\n",
        "        '''\n",
        "        Recall.\n",
        "        '''\n",
        "        return self.tpr\n",
        "\n",
        "    @property\n",
        "    def f1_score(self) -> float:\n",
        "        '''\n",
        "        F1 score.\n",
        "        '''\n",
        "        summ = self.precision + self.recall\n",
        "        return 0. if summ == 0 else 2*self.precision*self.recall/summ\n",
        "\n",
        "    def fbeta_score(self, beta: float) -> float:\n",
        "        '''\n",
        "        F-beta score.\n",
        "        '''\n",
        "        summ = beta**2*self.precision + self.recall\n",
        "        return 0. if summ == 0 else \\\n",
        "            (1 + beta**2)*self.precision*self.recall/summ\n",
        "\n",
        "    @property\n",
        "    def iou(self) -> float:\n",
        "        '''\n",
        "        Intersection Over Union.\n",
        "        '''\n",
        "        summ = self.tp + self.fp + self.fn\n",
        "        return 0. if summ == 0 else self.tp/summ\n",
        "\n",
        "    def as_json_dict(self) -> Dict[str, Union[int, float]]:\n",
        "        '''\n",
        "        Metrics as jsonifiable dictionary.\n",
        "        '''\n",
        "        data = super().as_json_dict()\n",
        "        data.update({\n",
        "            'tp': self.tp,\n",
        "            'tn': self.tn,\n",
        "            'fp': self.fp,\n",
        "            'fn': self.fn,\n",
        "            'n_pos': self.n_pos,\n",
        "            'n_neg': self.n_neg,\n",
        "            'tpr': self.tpr,\n",
        "            'tnr': self.tnr,\n",
        "            'fpr': self.fpr,\n",
        "            'fnr': self.fnr,\n",
        "            'iou': self.iou,\n",
        "            'precision': self.precision,\n",
        "            'recall': self.recall,\n",
        "            'f1_score': self.f1_score,\n",
        "        })\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA1efbtSxD5T"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Module for covr metric.\n",
        "'''\n",
        "\n",
        "from collections import namedtuple\n",
        "from typing import List\n",
        "from skimage import measure as meas\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "Labeling = namedtuple('Labeling', [\n",
        "    'img',\n",
        "    'props',\n",
        "])\n",
        "\n",
        "\n",
        "Isection = namedtuple('Isection', [\n",
        "    'yt_label',\n",
        "    'yp_label',\n",
        "    'prop',\n",
        "])\n",
        "\n",
        "\n",
        "IntersectionGroup = namedtuple('IntersectionGroup', [\n",
        "    'yt_lab',\n",
        "    'yp_lab',\n",
        "    'isect_lab',\n",
        "    'isections',\n",
        "])\n",
        "\n",
        "CoverageResult = namedtuple('CoverageResult', [\n",
        "    'n_labels',\n",
        "    'n_cov_labels',\n",
        "])\n",
        "\n",
        "\n",
        "IsectionProps = namedtuple('IsectionProps', [\n",
        "    'yt_label',\n",
        "    'yt_area',\n",
        "    'yp_label',\n",
        "    'yp_area',\n",
        "    'isect_label',\n",
        "    'isect_area',\n",
        "])\n",
        "\n",
        "\n",
        "def _label(mask):\n",
        "    labels_img = meas.label(mask, connectivity=2,\n",
        "                            background=0, return_num=False)\n",
        "    props = meas.regionprops(labels_img, cache=True)\n",
        "    props = {p.label: p for p in props}\n",
        "    return Labeling(labels_img, props)\n",
        "\n",
        "\n",
        "def _get_isection_group(yt, yp):\n",
        "    yt_lab = _label(yt)\n",
        "    yp_lab = _label(yp)\n",
        "    isect = yt & yp\n",
        "    isect_lab = _label(isect)\n",
        "\n",
        "    elems = []\n",
        "    for prop in isect_lab.props.values():\n",
        "        i, j = next(iter(prop.coords))\n",
        "        elems.append(Isection(\n",
        "            yt_label=yt_lab.img[i, j],\n",
        "            yp_label=yp_lab.img[i, j],\n",
        "            prop=prop))\n",
        "\n",
        "    return IntersectionGroup(\n",
        "        yt_lab=yt_lab,\n",
        "        yp_lab=yp_lab,\n",
        "        isect_lab=isect_lab,\n",
        "        isections=elems)\n",
        "\n",
        "\n",
        "def _get_isection_props(isect_group):\n",
        "    properties = []\n",
        "    for isect in isect_group.isections:\n",
        "        properties.append(IsectionProps(\n",
        "            yt_label=isect.yt_label,\n",
        "            yt_area=isect_group.yt_lab.props[isect.yt_label].area,\n",
        "            yp_label=isect.yp_label,\n",
        "            yp_area=isect_group.yp_lab.props[isect.yp_label].area,\n",
        "            isect_label=isect.prop.label,\n",
        "            isect_area=isect.prop.area\n",
        "        ))\n",
        "    return properties\n",
        "\n",
        "\n",
        "def _get_nearest_yp(isection_props):\n",
        "    matches = {}\n",
        "    for prop in isection_props:\n",
        "        key = prop.yp_label\n",
        "        if key not in matches or prop.isect_area > matches[key].isect_area:\n",
        "            matches[key] = prop\n",
        "    return matches\n",
        "\n",
        "\n",
        "def _get_coverage(isection_props, min_yt_frac=0.1, min_yp_frac=0.5):\n",
        "    coverage = []\n",
        "    cands = _get_nearest_yp(isection_props)\n",
        "\n",
        "    for prop in cands.values():\n",
        "        yt_frac = prop.isect_area/max(prop.yt_area, 1)\n",
        "        if yt_frac < min_yt_frac:\n",
        "            continue\n",
        "        yp_frac = prop.isect_area/max(prop.yp_area, 1)\n",
        "        if yp_frac < min_yp_frac:\n",
        "            continue\n",
        "        coverage.append(prop)\n",
        "\n",
        "    return coverage\n",
        "\n",
        "\n",
        "def _get_coverage_numbers(yt, yp):\n",
        "    isect_group = _get_isection_group(yt, yp)\n",
        "    isect_props = _get_isection_props(isect_group)\n",
        "    coverage = _get_coverage(isect_props)\n",
        "\n",
        "    n_yt_labels = len(isect_group.yt_lab.props)\n",
        "    n_cov_yt_labels = len({p.yt_label for p in coverage})\n",
        "\n",
        "    return CoverageResult(\n",
        "        n_labels=n_yt_labels,\n",
        "        n_cov_labels=n_cov_yt_labels)\n",
        "\n",
        "\n",
        "class CoverageMetric(ClassificationMetrics):\n",
        "    '''\n",
        "    Coverage Metric for multi-class predictor classification.\n",
        "    '''\n",
        "\n",
        "    @classmethod\n",
        "    def get_coverage_ratio(cls, yts: List[np.ndarray],\n",
        "                           yps: List[np.ndarray], thr: str = 0.5) -> float:\n",
        "        \"\"\"\n",
        "        Get coverage ratio metric based on ground truth and predictions.\n",
        "\n",
        "        Args:\n",
        "            yts: Ground truths\n",
        "            yps: predictions\n",
        "            thr: Threshold to convert predictions to mask. Defaults to 0.5\n",
        "\n",
        "        Returns:\n",
        "            Coverage ratio metric for ground truth and predictions.\n",
        "        \"\"\"\n",
        "        n_labels = 0\n",
        "        n_cov_labels = 0\n",
        "\n",
        "        for yt, yp in zip(yts, yps):\n",
        "            yp = (yp >= thr).astype('uint8')\n",
        "            cov = _get_coverage_numbers(yt, yp)\n",
        "            n_labels += cov.n_labels\n",
        "            n_cov_labels += cov.n_cov_labels\n",
        "\n",
        "        ratio = n_cov_labels/max(n_labels, 1)\n",
        "        return ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxHxppDJsn41"
      },
      "outputs": [],
      "source": [
        "class LossFunctions:\n",
        "    \"\"\"\n",
        "    A collection of loss functions and corresponding metrics for image segmentation tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def binary_crossentropy():\n",
        "        \"\"\"\n",
        "        Returns the binary cross-entropy loss function configured with from_logits=True.\n",
        "\n",
        "        Returns:\n",
        "            An instance of tf.keras.losses.BinaryCrossentropy configured with from_logits=True.\n",
        "        \"\"\"\n",
        "        return tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    def binary_accuracy():\n",
        "        \"\"\"\n",
        "        Returns the binary accuracy metric.\n",
        "\n",
        "        Returns:\n",
        "            An instance of tf.keras.metrics.BinaryAccuracy.\n",
        "        \"\"\"\n",
        "        return tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "        \"\"\"\n",
        "        Computes the Dice Coefficient, a measure of overlap between true and predicted labels.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            smooth: A smoothing constant to avoid division by zero.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Dice Coefficient.\n",
        "        \"\"\"\n",
        "        y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "    def dice_loss(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Computes the Dice Loss, derived from the Dice Coefficient, used to maximize overlap.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Dice Loss.\n",
        "        \"\"\"\n",
        "        return 1 - LossFunctions.dice_coefficient(y_true, y_pred)\n",
        "\n",
        "    def jaccard_index(y_true, y_pred, smooth=1):\n",
        "        \"\"\"\n",
        "        Computes the Jaccard Index, also known as Intersection over Union (IoU),\n",
        "        which measures the overlap between true and predicted labels.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            smooth: A smoothing constant to avoid division by zero.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Jaccard Index.\n",
        "        \"\"\"\n",
        "        y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        sum_ = K.sum(y_true_f) + K.sum(y_pred_f)\n",
        "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "        return jac\n",
        "\n",
        "    def jaccard_loss(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Computes the Jaccard Loss, derived from the Jaccard Index, used to maximize\n",
        "        the intersection over union.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Jaccard Loss.\n",
        "        \"\"\"\n",
        "        return 1 - LossFunctions.jaccard_index(y_true, y_pred)\n",
        "\n",
        "    def tversky_index(y_true, y_pred, alpha=0.5, beta=0.5, smooth=1):\n",
        "        \"\"\"\n",
        "        Computes the Tversky Index, a generalized form of the Dice Coefficient,\n",
        "        that introduces a weighting between false positives and false negatives.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            alpha: Weight for false negatives.\n",
        "            beta: Weight for false positives.\n",
        "            smooth: A smoothing constant to avoid division by zero.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Tversky Index.\n",
        "        \"\"\"\n",
        "        y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        true_pos = K.sum(y_true_f * y_pred_f)\n",
        "        false_neg = K.sum(y_true_f * (1 - y_pred_f))\n",
        "        false_pos = K.sum((1 - y_true_f) * y_pred_f)\n",
        "        return (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
        "\n",
        "    def tversky_loss(y_true, y_pred, alpha=0.5, beta=0.5):\n",
        "        \"\"\"\n",
        "        Computes the Tversky Loss, derived from the Tversky Index, used to handle\n",
        "        class imbalance by adjusting the penalty for false positives and false negatives.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            alpha: Weight for false negatives.\n",
        "            beta: Weight for false positives.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Tversky Loss.\n",
        "        \"\"\"\n",
        "        return 1 - LossFunctions.tversky_index(y_true, y_pred, alpha, beta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCB9QdZUlIuE"
      },
      "outputs": [],
      "source": [
        "class BaseImageProcess:\n",
        "    \"\"\"\n",
        "    BaseImageProcess: A base class for image processing algorithms.\n",
        "\n",
        "    This class provides a basic framework for implementing image processing algorithms and is intended to be subclassed.\n",
        "    Subclasses should implement the `apply` method to perform specific image processing operations on an input image.\n",
        "    \"\"\"\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        \"\"\"\n",
        "        Placeholder for applying an image processing algorithm.\n",
        "\n",
        "        Args:\n",
        "            img: The input image to process.\n",
        "\n",
        "        Returns:\n",
        "            The processed image.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class Rotate(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.angle = random.choice([-15, -10, -5, 5, 10, 15])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        height, width = img.shape[:2]\n",
        "        rotation_matrix = cv.getRotationMatrix2D((width / 2, height / 2), self.angle, 1)\n",
        "        return cv.warpAffine(img, rotation_matrix, (width, height)), (\n",
        "            cv.warpAffine(mask, rotation_matrix, (width, height))\n",
        "            if mask is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "\n",
        "class BilateralFilter(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    BilateralFilter: Applies bilateral filtering to an image to reduce noise while keeping edges sharp.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d=9, sigmaColor=75, sigmaSpace=75):\n",
        "        self.d = d\n",
        "        self.sigmaColor = sigmaColor\n",
        "        self.sigmaSpace = sigmaSpace\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.bilateralFilter(img, self.d, self.sigmaColor, self.sigmaSpace), mask\n",
        "\n",
        "\n",
        "class Translate(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Applies translation to an image using random horizontal and vertical shifts.\n",
        "\n",
        "    Attributes:\n",
        "        dx (int): Horizontal shift, chosen randomly from a specified range.\n",
        "        dy (int): Vertical shift, chosen randomly from a specified range.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dx = random.choice([-10, -5, 0, 5, 10])\n",
        "        self.dy = random.choice([-10, -5, 0, 5, 10])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        translation_matrix = np.float32([[1, 0, self.dx], [0, 1, self.dy]])\n",
        "        height, width = img.shape[:2]\n",
        "        return cv.warpAffine(img, translation_matrix, (width, height)), (\n",
        "            cv.warpAffine(mask, translation_matrix, (width, height))\n",
        "            if mask is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "\n",
        "class Flip(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Flips an image either horizontally, vertically, or both, based on a randomly selected flip type.\n",
        "\n",
        "    Attributes:\n",
        "        flip_type (int): Type of flip to apply; -1 for both axes, 0 for vertical, 1 for horizontal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.flip_type = random.choice([-1, 0, 1])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.flip(img, self.flip_type), (\n",
        "            cv.flip(mask, self.flip_type) if mask is not None else None\n",
        "        )\n",
        "\n",
        "\n",
        "class BrightnessContrast(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Adjusts the brightness and contrast of an image using random values.\n",
        "\n",
        "    Attributes:\n",
        "        alpha (float): Factor by which the contrast will be adjusted.\n",
        "        beta (int): Value that will be added to the pixels for brightness adjustment.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.alpha = random.uniform(0.5, 1.5)\n",
        "        self.beta = random.randint(-50, 50)\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.convertScaleAbs(img, alpha=self.alpha, beta=self.beta), mask\n",
        "\n",
        "\n",
        "class MedianBlur(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Applies median blurring to an image using a randomly chosen kernel size.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): The size of the kernel used, selected randomly from a set of possible odd sizes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.kernel_size = random.choice([3, 5, 7, 9, 11])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.medianBlur(img, self.kernel_size), mask\n",
        "\n",
        "\n",
        "class RandomGaussianBlur(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Applies Gaussian blur filtering to an image with a randomly chosen kernel size.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the Gaussian blur kernel, selected randomly.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.kernel_size = random.choice([3, 5, 7, 9, 11])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.GaussianBlur(img, (self.kernel_size, self.kernel_size), 0), mask\n",
        "\n",
        "\n",
        "class GaussianBlur(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    GaussianBlur: Applies Gaussian blur filtering to an image.\n",
        "\n",
        "    This class provides an implementation of Gaussian blur filtering, commonly used to reduce image noise and detail.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the kernel used for the Gaussian filter.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size=5):\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.GaussianBlur(img, (self.kernel_size, self.kernel_size), 0), mask\n",
        "\n",
        "\n",
        "class BinaryThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    BinaryThresh: Applies binary thresholding to an image.\n",
        "\n",
        "    Binary thresholding converts an image to binary (black and white) based on a threshold value. Pixels above the\n",
        "    threshold are set to the maximum value, and those below are set to zero.\n",
        "\n",
        "    Attributes:\n",
        "        thresh (int): Threshold value.\n",
        "        max_val (int): Maximum value to use with the threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresh=127, max_val=255):\n",
        "        self.thresh = thresh\n",
        "        self.max_val = max_val\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        _, _img = cv.threshold(_img, self.thresh, self.max_val, cv.THRESH_BINARY)\n",
        "        return _img, mask\n",
        "\n",
        "\n",
        "class AdaptiveMeanThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    AdaptiveMeanThresh: Applies adaptive mean thresholding to an image.\n",
        "\n",
        "    Unlike simple thresholding, adaptive thresholding changes the threshold dynamically over the image based on local\n",
        "    image characteristics.\n",
        "\n",
        "    Attributes:\n",
        "        block_size (int): Size of a pixel neighborhood used to calculate the threshold.\n",
        "        c (int): Constant subtracted from the calculated mean or weighted mean.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, block_size=11, c=2):\n",
        "        self.block_size = block_size\n",
        "        self.c = c\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        return (\n",
        "            cv.adaptiveThreshold(\n",
        "                _img,\n",
        "                255,\n",
        "                cv.ADAPTIVE_THRESH_MEAN_C,\n",
        "                cv.THRESH_BINARY,\n",
        "                self.block_size,\n",
        "                self.c,\n",
        "            ),\n",
        "            mask,\n",
        "        )\n",
        "\n",
        "\n",
        "class AdaptiveGaussThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    AdaptiveGaussThresh: Applies adaptive Gaussian thresholding to an image.\n",
        "\n",
        "    This method uses a weighted sum of neighbourhood values where weights are a Gaussian window, which provides\n",
        "    a more natural thresholding, especially under varying illumination.\n",
        "\n",
        "    Attributes:\n",
        "        block_size (int): Size of a pixel neighborhood used to calculate the threshold.\n",
        "        c (int): Constant subtracted from the calculated weighted sum.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, block_size=11, c=2):\n",
        "        self.block_size = block_size\n",
        "        self.c = c\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        return (\n",
        "            cv.adaptiveThreshold(\n",
        "                _img,\n",
        "                255,\n",
        "                cv.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                cv.THRESH_BINARY,\n",
        "                self.block_size,\n",
        "                self.c,\n",
        "            ),\n",
        "            mask,\n",
        "        )\n",
        "\n",
        "\n",
        "class OtsuThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    OtsuThresh: Applies Otsu's thresholding to automatically perform histogram shape-based image thresholding.\n",
        "\n",
        "    This method is useful when the image contains two prominent pixel intensities and calculates an optimal threshold\n",
        "    separating these two classes so that their combined spread (intra-class variance) is minimal.\n",
        "    \"\"\"\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        _, _img = cv.threshold(_img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
        "        return _img, mask\n",
        "\n",
        "\n",
        "class MorphDilate(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    MorphDilate: Applies morphological dilation to an image.\n",
        "\n",
        "    Dilation increases the white region in the image or size of the foreground object. Commonly used to accentuate\n",
        "    features.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the structuring element.\n",
        "        iterations (int): Number of times dilation is applied.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size=3, iterations=2):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.iterations = iterations\n",
        "        self.kernel = np.ones((self.kernel_size, self.kernel_size), np.uint8)\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.dilate(img, self.kernel, iterations=self.iterations), mask\n",
        "\n",
        "\n",
        "class MorphErode(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    MorphErode: Applies morphological erosion to an image.\n",
        "\n",
        "    Erosion erodes away the boundaries of the foreground object and is used to diminish the features of an image.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the structuring element.\n",
        "        iterations (int): Number of times erosion is applied.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size=3, iterations=2):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.iterations = iterations\n",
        "        self.kernel = np.ones((self.kernel_size, self.kernel_size), np.uint8)\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.erode(img, self.kernel, iterations=self.iterations), mask\n",
        "\n",
        "\n",
        "class LoG(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    LoG: Applies Laplacian of Gaussian filtering to an image.\n",
        "\n",
        "    This method is used to highlight regions of rapid intensity change and is therefore often used for edge detection.\n",
        "    First, it applies a Gaussian blur, then computes the Laplacian of the result.\n",
        "\n",
        "    Attributes:\n",
        "        sigma (float): Standard deviation of the Gaussian filter.\n",
        "        size (int): Size of the filter kernel.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sigma=2.0, size=None):\n",
        "        self.sigma = sigma\n",
        "        self.size = (\n",
        "            size\n",
        "            if size is not None\n",
        "            else int(6 * self.sigma + 1) if self.sigma >= 1 else 7\n",
        "        )\n",
        "        if self.size % 2 == 0:\n",
        "            self.size += 1\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        x, y = np.meshgrid(\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "        )\n",
        "        kernel = (\n",
        "            -(1 / (np.pi * self.sigma**4))\n",
        "            * (1 - ((x**2 + y**2) / (2 * self.sigma**2)))\n",
        "            * np.exp(-(x**2 + y**2) / (2 * self.sigma**2))\n",
        "        )\n",
        "        kernel = kernel / np.sum(np.abs(kernel))\n",
        "        return cv.filter2D(img, -1, kernel), mask\n",
        "\n",
        "\n",
        "class LoGConv(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    LoGConv: Implements convolution with a Laplacian of Gaussian kernel to an image.\n",
        "\n",
        "    Similar to the LoG class, but tailored for applying custom convolution operations directly with a manually\n",
        "    crafted LoG kernel.\n",
        "\n",
        "    Attributes:\n",
        "        sigma (float): Standard deviation of the Gaussian filter.\n",
        "        size (int): Size of the filter kernel.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sigma=2.0, size=None):\n",
        "        self.sigma = sigma\n",
        "        self.size = size if size is not None else int(6 * sigma + 1)\n",
        "        if self.size % 2 == 0:\n",
        "            self.size += 1\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        if len(img.shape) == 3:\n",
        "            img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        x, y = np.meshgrid(\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "        )\n",
        "        kernel = (\n",
        "            -(1 / (np.pi * self.sigma**4))\n",
        "            * (1 - ((x**2 + y**2) / (2 * self.sigma**2)))\n",
        "            * np.exp(-(x**2 + y**2) / (2 * self.sigma**2))\n",
        "        )\n",
        "        kernel = kernel / np.sum(np.abs(kernel))\n",
        "        if len(img.shape) == 3:\n",
        "            img = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
        "            img = convolve(img, kernel)\n",
        "            img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "        else:\n",
        "            img = convolve(img, kernel)\n",
        "        return img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6VNJogAoTRt"
      },
      "outputs": [],
      "source": [
        "class ImageAdjustments(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    ImageAdjustments: Applies various adjustments to an image such as brightness, gamma, contrast,\n",
        "    shadows, highlights, sharpness, and blur.\n",
        "    Attributes:\n",
        "        brightness (float): The factor by which to adjust the brightness.\n",
        "        gamma (float): The gamma correction value.\n",
        "        contrast (float): The factor by which to adjust the contrast.\n",
        "        shadows (int): The percentage of shadows to cut off.\n",
        "        highlights (int): The percentage of highlights to cut off.\n",
        "        sharpness (float): The factor by which to adjust the sharpness.\n",
        "        blur (float): The blur radius.\n",
        "    \"\"\"\n",
        "    def __init__(self, brightness=1.0, gamma=1.0, contrast=1.0, shadows=0, highlights=0, sharpness=1.0, blur=0):\n",
        "        self.brightness = brightness\n",
        "        self.gamma = gamma\n",
        "        self.contrast = contrast\n",
        "        self.shadows = shadows\n",
        "        self.highlights = highlights\n",
        "        self.sharpness = sharpness\n",
        "        self.blur = blur\n",
        "    def adjust_brightness(self, image):\n",
        "        enhancer = ImageEnhance.Brightness(image)\n",
        "        return enhancer.enhance(self.brightness)\n",
        "    def adjust_gamma(self, image):\n",
        "        gamma_inv = 1.0 / self.gamma\n",
        "        lut = [pow(x / 255., gamma_inv) * 255 for x in range(256)]\n",
        "        lut = np.array(lut, dtype='uint8')\n",
        "        return Image.fromarray(lut[image])\n",
        "    def adjust_contrast(self, image):\n",
        "        enhancer = ImageEnhance.Contrast(image)\n",
        "        return enhancer.enhance(self.contrast)\n",
        "    def adjust_shadows_highlights(self, image):\n",
        "        if self.shadows > 0:\n",
        "            image = ImageOps.autocontrast(image, cutoff=self.shadows)\n",
        "        if self.highlights > 0:\n",
        "            image = ImageOps.autocontrast(image, cutoff=100 - self.highlights)\n",
        "        return image\n",
        "    def adjust_sharpen(self, image):\n",
        "        enhancer = ImageEnhance.Sharpness(image)\n",
        "        return enhancer.enhance(self.sharpness)\n",
        "    def adjust_blur(self, image):\n",
        "        return image.filter(ImageFilter.GaussianBlur(self.blur))\n",
        "    def apply(self, img, mask=None):\n",
        "        if isinstance(img, np.ndarray):\n",
        "            img = Image.fromarray(img)\n",
        "        img = self.adjust_brightness(img)\n",
        "        img = self.adjust_gamma(img)\n",
        "        img = self.adjust_contrast(img)\n",
        "        img = self.adjust_shadows_highlights(img)\n",
        "        img = self.adjust_sharpen(img)\n",
        "        img = self.adjust_blur(img)\n",
        "        img = np.array(img)\n",
        "        return img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Q3h-vViEX6"
      },
      "outputs": [],
      "source": [
        "class SobelFilter(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    SobelFilter: Applies Sobel filtering to an image.\n",
        "\n",
        "    This method is used to highlight edges in the image by calculating the gradient magnitude.\n",
        "\n",
        "    Attributes:\n",
        "        ksize (int): Size of the extended Sobel kernel; it must be 1, 3, 5, or 7.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ksize=3):\n",
        "        self.ksize = ksize\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        # Convert to grayscale if the image is in color\n",
        "        if len(img.shape) == 3:\n",
        "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray = img\n",
        "\n",
        "        # Apply Sobel filter\n",
        "        grad_x = cv.Sobel(gray, cv.CV_64F, 1, 0, ksize=self.ksize)\n",
        "        grad_y = cv.Sobel(gray, cv.CV_64F, 0, 1, ksize=self.ksize)\n",
        "\n",
        "        # Compute gradient magnitude\n",
        "        grad = cv.magnitude(grad_x, grad_y)\n",
        "\n",
        "        # Normalize the gradient to the range 0-255\n",
        "        grad = cv.normalize(grad, None, 0, 255, cv.NORM_MINMAX)\n",
        "        grad = grad.astype(np.uint8)\n",
        "\n",
        "        # Apply color map for better visualization\n",
        "        color_grad = cv.applyColorMap(grad, cv.COLORMAP_JET)\n",
        "\n",
        "        return color_grad, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbtOnKhZl_8k"
      },
      "outputs": [],
      "source": [
        "def load_image(path, color_mode=cv.IMREAD_COLOR):\n",
        "    \"\"\"Loads an image from the given path with specified color mode.\"\"\"\n",
        "    image = cv.imread(path, color_mode)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Could not load image from {path}\")\n",
        "    return image\n",
        "\n",
        "def display_history(history):\n",
        "    n_images = len(history)\n",
        "    n_rows = math.ceil(n_images ** 0.5)\n",
        "    n_cols = math.ceil(n_images / n_rows)\n",
        "    plt.figure(figsize=(n_cols * 4, n_rows * 4))\n",
        "    for i, (img, label, _) in enumerate(history):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def get_dataset(batch_size,\n",
        "    img_size,\n",
        "    input_img_arr,\n",
        "    target_img_arr,\n",
        "    max_dataset_len=None,\n",
        "):\n",
        "    \"\"\"Returns a TF Dataset.\"\"\"\n",
        "    if max_dataset_len:\n",
        "        input_img_arr = input_img_arr[:max_dataset_len]\n",
        "        target_img_arr = target_img_arr[:max_dataset_len]\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((input_img_arr, target_img_arr))\n",
        "    return dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj3yyp_Alq3y"
      },
      "outputs": [],
      "source": [
        "class ImageDataManager:\n",
        "    \"\"\"\n",
        "    A class used to manage image data for processing and analysis.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    objects : dict\n",
        "        A dictionary to store processed image data with mask IDs as keys.\n",
        "    base_masks_path : str\n",
        "        Path to the directory containing mask images.\n",
        "    base_inputs_path : str\n",
        "        Path to the directory containing input images.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    process_images()\n",
        "        Processes all images found in the base paths and populates the objects dictionary.\n",
        "    process_input_folder(input_folder_path)\n",
        "        Processes all images within a given input folder path and returns a list of images.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_masks_path, base_inputs_path):\n",
        "        \"\"\"\n",
        "        Constructs all the necessary attributes for the ImageDataManager object.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        base_masks_path : str\n",
        "            Path to the directory containing mask images.\n",
        "        base_inputs_path : str\n",
        "            Path to the directory containing input images.\n",
        "        \"\"\"\n",
        "        self.objects = {}\n",
        "        self.base_masks_path = base_masks_path\n",
        "        self.base_inputs_path = base_inputs_path\n",
        "        self.process_images()\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image(image_path, flags=cv.IMREAD_COLOR):\n",
        "        \"\"\"\n",
        "        Loads an image from a specified path.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        image_path : str\n",
        "            Path to the image file to be loaded.\n",
        "        flags : int\n",
        "            Flags for image color format to be read.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        ndarray\n",
        "            The image loaded into memory.\n",
        "        \"\"\"\n",
        "        return cv.imread(image_path, flags)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_channels(image_path):\n",
        "        \"\"\"\n",
        "        Splits the channels of an image at the given path.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        image_path : str\n",
        "            Path to the image file.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            A list containing the channels of the image.\n",
        "        \"\"\"\n",
        "        image = cv.imread(image_path, cv.IMREAD_UNCHANGED)\n",
        "        channels = cv.split(image)\n",
        "        if len(channels) == 4:\n",
        "            return channels[:3]  # Ignore alpha channel\n",
        "        return channels\n",
        "\n",
        "    def process_images(self):\n",
        "        \"\"\"\n",
        "        Processes the images found in the base paths and stores them in the objects dictionary.\n",
        "        \"\"\"\n",
        "        files = os.listdir(self.base_masks_path)\n",
        "        print(files)\n",
        "        files = files[:-1]\n",
        "        print(files)\n",
        "\n",
        "        for mask_filename in files:\n",
        "            if mask_filename.endswith('.png'):\n",
        "                mask_id = os.path.splitext(mask_filename)[0]\n",
        "                mask_path = os.path.join(self.base_masks_path, mask_filename)\n",
        "                mask = self.load_image(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "                input_folder_path = os.path.join(self.base_inputs_path, mask_id)\n",
        "                images = self.process_input_folder(input_folder_path)\n",
        "                self.objects[int(mask_id)] = {\n",
        "                    'mask': mask,\n",
        "                    'input': input_folder_path,\n",
        "                    'images': images\n",
        "                }\n",
        "\n",
        "    def process_input_folder(self, input_folder_path):\n",
        "        \"\"\"\n",
        "        Processes all images within the given input folder path.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_folder_path : str\n",
        "            Path to the input folder containing image files.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            A list of processed images.\n",
        "        \"\"\"\n",
        "        images = []\n",
        "        if os.path.isdir(input_folder_path):\n",
        "            for image_filename in os.listdir(input_folder_path):\n",
        "                image_path = os.path.join(input_folder_path, image_filename)\n",
        "                if image_filename.endswith('.png'):\n",
        "                    channels = self.split_channels(image_path)\n",
        "                    images.append(np.array(channels))\n",
        "                elif image_filename.endswith(('.tif', '.tiff')):\n",
        "                    tif_image = self.load_image(image_path, cv.IMREAD_UNCHANGED)\n",
        "                    images.append(np.array([tif_image]))\n",
        "        return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o2v4KtnkT1u"
      },
      "source": [
        "## Pipeline de pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4KapMTSYi-v",
        "outputId": "eb056484-54cf-4f9a-a53a-11ec2cf4e47d"
      },
      "outputs": [],
      "source": [
        "n_augmented = 0\n",
        "filters = [ImageAdjustments()]\n",
        "augmentations = [Rotate(), Translate(), Flip(), BrightnessContrast(), RandomGaussianBlur(), MedianBlur()]\n",
        "\n",
        "pipeline = Pipeline.ProcessingPipeline()\n",
        "pipeline.add_filters(filters)\n",
        "pipeline.add_augmentations(augmentations)\n",
        "\n",
        "base_masks_path = \"/content/drive/MyDrive/grupo1/Images/Masks\"\n",
        "base_inputs_path = \"/content/drive/MyDrive/grupo1/Images/Input\"\n",
        "image_data_manager = ImageDataManager(base_masks_path, base_inputs_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Uw-XznMsmJk1"
      },
      "outputs": [],
      "source": [
        "images_np_array = []\n",
        "masks_np_array = []\n",
        "\n",
        "for key in image_data_manager.objects.keys():\n",
        "  imgs = image_data_manager.objects[key]['images'][:]\n",
        "  imgs_filtered = []\n",
        "\n",
        "  for img in imgs:\n",
        "    if img.shape[1] == 1200:\n",
        "      imgs_filtered.append(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "  image_data_manager.objects[key]['images'] = imgs_filtered\n",
        "  mask = image_data_manager.objects[key]['mask']\n",
        "  image_data_manager.objects[key]['mask'] = mask\n",
        "  img = imgs_filtered[-1]\n",
        "\n",
        "\n",
        "\n",
        "  n_crop = img.shape[0] // 128\n",
        "  imgs, masks, coordinates = pipeline.run(img, mask, crop_size=128, n_crop=n_crop, n_augmented=n_augmented)\n",
        "\n",
        "  to_aggregate_imgs = imgs_filtered[:-1]\n",
        "\n",
        "  # for i in range(len(imgs)):\n",
        "  #   _img = imgs[i]\n",
        "  #   _coord = coordinates[i]\n",
        "  #   for _to_agg in to_aggregate_imgs:\n",
        "  #     crop = _to_agg[_coord[1]:128,_coord[0]:128]\n",
        "  #     print(\"ok\")\n",
        "\n",
        "  # for _img, _coord in enumerate(zip(imgs, coordinates)):\n",
        "  #   for to_agg in to_aggregate_imgs:\n",
        "  #     print(_coord)\n",
        "  #     crop = to_agg[_coord[1]:128,_coord[0]:128]\n",
        "  #     cv.imshow('cropped', crop)\n",
        "\n",
        "  images_np_array.extend(imgs)\n",
        "  masks_np_array.extend(masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GQZumFGnYXF"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1rebgoAf1Lu"
      },
      "outputs": [],
      "source": [
        "val_samples = int(len(images_np_array) * 0.2)\n",
        "train_input_img_sample = images_np_array[:-val_samples]\n",
        "train_target_img_sample = masks_np_array[:-val_samples]\n",
        "val_input_img_sample = images_np_array[-val_samples:]\n",
        "val_target_img_sample = masks_np_array[-val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFK8twPR8f3b"
      },
      "outputs": [],
      "source": [
        "filtered = train_input_img_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j79uAm2nf96"
      },
      "outputs": [],
      "source": [
        "img_size = (128,128)\n",
        "batch_size = 1\n",
        "\n",
        "# training dataset\n",
        "train_dataset = get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    train_input_img_sample,\n",
        "    train_target_img_sample,\n",
        "    max_dataset_len=2000,\n",
        ")\n",
        "\n",
        "# validation dataset\n",
        "valid_dataset = get_dataset(\n",
        "    batch_size, img_size, val_input_img_sample, val_target_img_sample\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLzuA67EkWBm"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OXGlogpSSvY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom, RandomWidth, RandomHeight\n",
        "import time\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "            RandomFlip(\"horizontal\"),\n",
        "            RandomRotation(0.2),\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "09LG2dfvn0lR",
        "outputId": "318d5531-c849-4153-9366-a4635c5afd6f"
      },
      "outputs": [],
      "source": [
        "# Importação do modelo pre-treinado\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "base_model = Model(inputs=base_model.input, outputs=base_model.layers[:-13][-1].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu5HKAUvYDE-"
      },
      "outputs": [],
      "source": [
        "# Novas camadas para adicionar ao modelo\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(base_model.output)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o4b9kZIWaMU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.00025),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[keras.metrics.BinaryAccuracy(), dice_coefficient]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"model.keras\", save_best_only=True),\n",
        "    #LearningRateScheduler(warmup_lr)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onhne4oxZ5TF",
        "outputId": "9f12e055-3028-4e1a-d653-9cdbc8383b2f"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=(valid_dataset),\n",
        "  epochs=50,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks\n",
        "  )\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKXNrpd3Sye0",
        "outputId": "bb7f5573-ef42-4343-b2b3-f9fa2af9e679"
      },
      "outputs": [],
      "source": [
        "print(f\"O treinamento do modelo VGG16 levou {training_time:.2f} segundos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDLlBhDuoWjD"
      },
      "source": [
        "## Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "XQoDfDMKoVt9",
        "outputId": "fdc05553-6ab5-4788-ffa0-c68ebb24ed14"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotando a precisão binária\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('Model Binary Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plotando o coeficiente Dice\n",
        "plt.plot(history.history['dice_coefficient'])\n",
        "plt.plot(history.history['val_dice_coefficient'])\n",
        "plt.title('Model Dice Coefficient')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "x-CcXzTMotoP",
        "outputId": "5aa4792f-0769-4ebc-df0b-bdd3fa7250f8"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2BVQDjKPQ2H"
      },
      "outputs": [],
      "source": [
        "true_labels = []\n",
        "inputs_img = []\n",
        "\n",
        "for inputs, batch_labels in valid_dataset:\n",
        "    true_labels.extend(batch_labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1diCrSqaIUa",
        "outputId": "2c501b0e-acc6-4d7c-bbea-7086c302e4e9"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "predicted_labels = model.predict(valid_dataset)\n",
        "\n",
        "end_time = time.time()\n",
        "inference_time = end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di1imZX3aLO0"
      },
      "outputs": [],
      "source": [
        "true_labels = np.array(true_labels).astype(np.uint8)\n",
        "predicted_labels = np.squeeze(np.array(predicted_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwXpcDnZvgSC",
        "outputId": "282b6261-1190-44e0-c23f-c289e72baf5c"
      },
      "outputs": [],
      "source": [
        "coverage_ratio = CoverageMetric.get_coverage_ratio(true_labels, predicted_labels)\n",
        "print('Coverage Ratio: ' + str(coverage_ratio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F5GdXY-Bq_-t",
        "outputId": "44174911-9023-428a-8b4a-99dd9e35cc77"
      },
      "outputs": [],
      "source": [
        "def plot_images(ground_truth, predicted):\n",
        "    num_images = len(predicted)\n",
        "    plt.figure(figsize=(10, 5 * num_images))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(num_images, 2, 2*i + 1)\n",
        "        plt.imshow(predicted[i], cmap='gray')\n",
        "        plt.title('Predicted')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_images, 2, 2*i + 2)\n",
        "        plt.imshow(ground_truth[i] * 255, cmap='gray')\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "plot_images(true_labels, predicted_labels[:20])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw_ddvrH8es4"
      },
      "outputs": [],
      "source": [
        "output = subprocess.check_output(['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits'])\n",
        "gpu_power = float(output.decode('utf-8').strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMzimd0LaX76",
        "outputId": "d14e8768-5fe7-49d8-cdd2-852e3a543435"
      },
      "outputs": [],
      "source": [
        "print(f'Training time: {training_time} seconds\\n\\n')\n",
        "print(f'Inference time: {inference_time} seconds\\n\\n')\n",
        "print(f'Memory usage: {psutil.virtual_memory().used} bytes\\n\\n')\n",
        "print(\"GPU power consumption: \", gpu_power, \" Watts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izk28tXxa-S6"
      },
      "source": [
        "CPU for 1 epoch\n",
        "\n",
        "Training time: 1641.9396698474884 seconds\n",
        "\n",
        "\n",
        "Inference time: 142.00052905082703 seconds\n",
        "\n",
        "\n",
        "Memory usage: 3638788096 bytes\n",
        "\n",
        "\n",
        "CPU power consumption:  85.4  Watts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtaMooGyCZe0"
      },
      "outputs": [],
      "source": [
        "test_image = cv.imread('/content/drive/MyDrive/Images/Input/591/591_2019-9-28_S2L1C_21JXG_TCI.png')\n",
        "test_mask = cv.imread('/content/drive/MyDrive/Images/Masks/591.png', cv.IMREAD_GRAYSCALE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W3W1JxCEyPo"
      },
      "outputs": [],
      "source": [
        "_cimgs, _cmasks, _ccoord = pipeline.run(test_image, test_mask, 0, crop_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbAs0THxGV9Z"
      },
      "outputs": [],
      "source": [
        "_ximgs_to_predict = []\n",
        "\n",
        "for _c in _cimgs:\n",
        "  _ximgs_to_predict.append(_c)\n",
        "\n",
        "_ximgs_to_predict= np.array(_ximgs_to_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_uUtuA_Ipah",
        "outputId": "afdc5b3a-105b-4e6f-ea62-d9512287ac99"
      },
      "outputs": [],
      "source": [
        "_ximgs_to_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zM1a58pCxwJ",
        "outputId": "40a97af3-5ebb-404f-a607-b87bd7bf5cd9"
      },
      "outputs": [],
      "source": [
        "test_prediction = model.predict(_ximgs_to_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLPqrdqnCxwK"
      },
      "outputs": [],
      "source": [
        "test_mask = np.array(_cmasks).astype(np.uint8)\n",
        "test_prediction = np.squeeze(np.array(test_prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Gml66niCFQ1",
        "outputId": "c47952e5-e79d-47af-cf60-12b9b3cbc4ec"
      },
      "outputs": [],
      "source": [
        "def plot_images(ground_truth, predicted):\n",
        "    num_images = len(predicted)\n",
        "    plt.figure(figsize=(10, 5 * num_images))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(num_images, 2, 2*i + 1)\n",
        "        plt.imshow(predicted[i], cmap='gray')\n",
        "        plt.title('Predicted')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_images, 2, 2*i + 2)\n",
        "        plt.imshow(ground_truth[i] * 255, cmap='gray')\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "plot_images(test_mask, test_prediction[:20])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yYTGyM_mlG5q"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
