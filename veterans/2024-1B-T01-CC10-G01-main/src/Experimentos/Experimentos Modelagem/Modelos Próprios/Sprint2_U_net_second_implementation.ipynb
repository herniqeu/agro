{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkqnud_vDgu7",
        "outputId": "e82a6319-f7cc-447a-b4f5-4c27376985b2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCUGVmxsG6a-",
        "outputId": "f4b8c1e9-37a3-4c3c-dcd8-2cbc5efa613c"
      },
      "outputs": [],
      "source": [
        "!pip install keras_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606neZm6E8YW",
        "outputId": "79a11a39-13b6-4d9f-a628-3bb40549543d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras_cv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, backend\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR =\" /content/drive/MyDrive/u-net_test\"\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 4\n",
        "OUT_CLASSES = 1\n",
        "TRAIN_SPLIT_RATIO = 0.90\n",
        "\n",
        "\n",
        "\n",
        "def load_paths(path, split_ratio):\n",
        "    images = sorted(glob(os.path.join(path, \"/content/drive/MyDrive/u-net_test/img/*\")))[:140]\n",
        "    masks = sorted(glob(os.path.join(path, \"/content/drive/MyDrive/u-net_test/masks/*\")))[:140]\n",
        "    len_ = int(len(images) * split_ratio)\n",
        "    return (images[:len_], masks[:len_]), (images[len_:], masks[len_:])\n",
        "\n",
        "\n",
        "def read_image(path, size, mode):\n",
        "    x = keras.utils.load_img(path, target_size=size, color_mode=mode)\n",
        "    x = keras.utils.img_to_array(x)\n",
        "    x = (x / 255.0).astype(np.float32)\n",
        "    return x\n",
        "\n",
        "\n",
        "def preprocess(x_batch, y_batch, img_size, out_classes):\n",
        "    def f(_x, _y):\n",
        "        _x, _y = _x.decode(), _y.decode()\n",
        "        _x = read_image(_x, (img_size, img_size), mode=\"rgb\")  # image\n",
        "        _y = read_image(_y, (img_size, img_size), mode=\"grayscale\")  # mask\n",
        "        return _x, _y\n",
        "\n",
        "    images, masks = tf.numpy_function(f, [x_batch, y_batch], [tf.float32, tf.float32])\n",
        "    images.set_shape([img_size, img_size, 3])\n",
        "    masks.set_shape([img_size, img_size, out_classes])\n",
        "    return images, masks\n",
        "\n",
        "\n",
        "def load_dataset(image_paths, mask_paths, img_size, out_classes, batch, shuffle=True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
        "    if shuffle:\n",
        "        dataset = dataset.cache().shuffle(buffer_size=1000)\n",
        "    dataset = dataset.map(\n",
        "        lambda x, y: preprocess(x, y, img_size, out_classes),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_paths, val_paths = load_paths(DATA_DIR, TRAIN_SPLIT_RATIO)\n",
        "\n",
        "train_dataset = load_dataset(\n",
        "    train_paths[0], train_paths[1], IMAGE_SIZE, OUT_CLASSES, BATCH_SIZE, shuffle=True\n",
        ")\n",
        "val_dataset = load_dataset(\n",
        "    val_paths[0], val_paths[1], IMAGE_SIZE, OUT_CLASSES, BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Train Dataset: {train_dataset}\")\n",
        "print(f\"Validation Dataset: {val_dataset}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "v758mNLSIBLG",
        "outputId": "91d0b4df-5a28-45af-c407-65ac55ffe0d5"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i + 1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(keras.utils.array_to_img(display_list[i]), cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for image, mask in val_dataset.take(1):\n",
        "    display([image[0], mask[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOc3CLe9Igv9",
        "outputId": "b82e1b92-b322-42a9-c233-1107128d8244"
      },
      "outputs": [],
      "source": [
        "print(f\"Unique values count: {len(np.unique((mask[0] * 255)))}\")\n",
        "print(\"Unique values:\")\n",
        "print(np.unique((mask[0] * 255)).astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RARRpDngV5lZ"
      },
      "outputs": [],
      "source": [
        "def basic_block(x_input, filters, stride=1, down_sample=None, activation=None):\n",
        "    \"\"\"Creates a residual(identity) block with two 3*3 convolutions.\"\"\"\n",
        "    residual = x_input\n",
        "\n",
        "    x = layers.Conv2D(filters, (3, 3), strides=stride, padding=\"same\", use_bias=False)(\n",
        "        x_input\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, (3, 3), strides=(1, 1), padding=\"same\", use_bias=False)(\n",
        "        x\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    if down_sample is not None:\n",
        "        residual = down_sample\n",
        "\n",
        "    x = layers.Add()([x, residual])\n",
        "\n",
        "    if activation is not None:\n",
        "        x = layers.Activation(activation)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def convolution_block(x_input, filters, dilation=1):\n",
        "    \"\"\"Apply convolution + batch normalization + relu layer.\"\"\"\n",
        "    x = layers.Conv2D(filters, (3, 3), padding=\"same\", dilation_rate=dilation)(x_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "def segmentation_head(x_input, out_classes, final_size):\n",
        "    \"\"\"Map each decoder stage output to model output classes.\"\"\"\n",
        "    x = layers.Conv2D(out_classes, kernel_size=(3, 3), padding=\"same\")(x_input)\n",
        "\n",
        "    if final_size is not None:\n",
        "        x = layers.Resizing(final_size[0], final_size[1])(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_resnet_block(_resnet, block_num):\n",
        "    \"\"\"Extract and return ResNet-34 block.\"\"\"\n",
        "    resnet_layers = [3, 4, 6, 3]  # ResNet-34 layer sizes at different block.\n",
        "    return keras.models.Model(\n",
        "        inputs=_resnet.get_layer(f\"v2_stack_{block_num}_block1_1_conv\").input,\n",
        "        outputs=_resnet.get_layer(\n",
        "            f\"v2_stack_{block_num}_block{resnet_layers[block_num]}_add\"\n",
        "        ).output,\n",
        "        name=f\"resnet34_block{block_num + 1}\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9s6OSi6WBkA"
      },
      "outputs": [],
      "source": [
        "def basnet_predict(input_shape, out_classes):\n",
        "    \"\"\"BASNet Prediction Module, it outputs coarse label map.\"\"\"\n",
        "    filters = 64\n",
        "    num_stages = 6\n",
        "\n",
        "    x_input = layers.Input(input_shape)\n",
        "\n",
        "    # -------------Encoder--------------\n",
        "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding=\"same\")(x_input)\n",
        "\n",
        "    resnet = keras_cv.models.ResNet34Backbone(\n",
        "        include_rescaling=False,\n",
        "    )\n",
        "\n",
        "    encoder_blocks = []\n",
        "    for i in range(num_stages):\n",
        "        if i < 4:  # First four stages are adopted from ResNet-34 blocks.\n",
        "            x = get_resnet_block(resnet, i)(x)\n",
        "            encoder_blocks.append(x)\n",
        "            x = layers.Activation(\"relu\")(x)\n",
        "        else:  # Last 2 stages consist of three basic resnet blocks.\n",
        "            x = layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "            x = basic_block(x, filters=filters * 8, activation=\"relu\")\n",
        "            x = basic_block(x, filters=filters * 8, activation=\"relu\")\n",
        "            x = basic_block(x, filters=filters * 8, activation=\"relu\")\n",
        "            encoder_blocks.append(x)\n",
        "\n",
        "    # -------------Bridge-------------\n",
        "    x = convolution_block(x, filters=filters * 8, dilation=2)\n",
        "    x = convolution_block(x, filters=filters * 8, dilation=2)\n",
        "    x = convolution_block(x, filters=filters * 8, dilation=2)\n",
        "    encoder_blocks.append(x)\n",
        "\n",
        "    # -------------Decoder-------------\n",
        "    decoder_blocks = []\n",
        "    for i in reversed(range(num_stages)):\n",
        "        if i != (num_stages - 1):  # Except first, scale other decoder stages.\n",
        "            shape = keras.backend.int_shape(x)\n",
        "            x = layers.Resizing(shape[1] * 2, shape[2] * 2)(x)\n",
        "\n",
        "        x = layers.concatenate([encoder_blocks[i], x], axis=-1)\n",
        "        x = convolution_block(x, filters=filters * 8)\n",
        "        x = convolution_block(x, filters=filters * 8)\n",
        "        x = convolution_block(x, filters=filters * 8)\n",
        "        decoder_blocks.append(x)\n",
        "\n",
        "    decoder_blocks.reverse()  # Change order from last to first decoder stage.\n",
        "    decoder_blocks.append(encoder_blocks[-1])  # Copy bridge to decoder.\n",
        "\n",
        "    # -------------Side Outputs--------------\n",
        "    decoder_blocks = [\n",
        "        segmentation_head(decoder_block, out_classes, input_shape[:2])\n",
        "        for decoder_block in decoder_blocks\n",
        "    ]\n",
        "\n",
        "    return keras.models.Model(inputs=[x_input], outputs=decoder_blocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoulVWOxWDvb"
      },
      "outputs": [],
      "source": [
        "def basnet_rrm(base_model, out_classes):\n",
        "    \"\"\"BASNet Residual Refinement Module(RRM) module, output fine label map.\"\"\"\n",
        "    num_stages = 4\n",
        "    filters = 64\n",
        "\n",
        "    x_input = base_model.output[0]\n",
        "\n",
        "    # -------------Encoder--------------\n",
        "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding=\"same\")(x_input)\n",
        "\n",
        "    encoder_blocks = []\n",
        "    for _ in range(num_stages):\n",
        "        x = convolution_block(x, filters=filters)\n",
        "        encoder_blocks.append(x)\n",
        "        x = layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "\n",
        "    # -------------Bridge--------------\n",
        "    x = convolution_block(x, filters=filters)\n",
        "\n",
        "    # -------------Decoder--------------\n",
        "    for i in reversed(range(num_stages)):\n",
        "        shape = keras.backend.int_shape(x)\n",
        "        x = layers.Resizing(shape[1] * 2, shape[2] * 2)(x)\n",
        "        x = layers.concatenate([encoder_blocks[i], x], axis=-1)\n",
        "        x = convolution_block(x, filters=filters)\n",
        "\n",
        "    x = segmentation_head(x, out_classes, None)  # Segmentation head.\n",
        "\n",
        "    # ------------- refined = coarse + residual\n",
        "    x = layers.Add()([x_input, x])  # Add prediction + refinement output\n",
        "\n",
        "    return keras.models.Model(inputs=[base_model.input], outputs=[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXlc2H9AWF7b"
      },
      "outputs": [],
      "source": [
        "def basnet(input_shape, out_classes):\n",
        "    \"\"\"BASNet, it's a combination of two modules\n",
        "    Prediction Module and Residual Refinement Module(RRM).\"\"\"\n",
        "\n",
        "    # Prediction model.\n",
        "    predict_model = basnet_predict(input_shape, out_classes)\n",
        "    # Refinement model.\n",
        "    refine_model = basnet_rrm(predict_model, out_classes)\n",
        "\n",
        "    output = [refine_model.output]  # Combine outputs.\n",
        "    output.extend(predict_model.output)\n",
        "\n",
        "    output = [layers.Activation(\"sigmoid\")(_) for _ in output]  # Activations.\n",
        "\n",
        "    return keras.models.Model(inputs=[predict_model.input], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCfTfmJtWI2G",
        "outputId": "0a75814e-6a7a-41a5-97b0-9fafa94dbc9b"
      },
      "outputs": [],
      "source": [
        "class BasnetLoss(keras.losses.Loss):\n",
        "    \"\"\"BASNet hybrid loss.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(name=\"basnet_loss\", **kwargs)\n",
        "        self.smooth = 1.0e-9\n",
        "\n",
        "        # Binary Cross Entropy loss.\n",
        "        self.cross_entropy_loss = keras.losses.BinaryCrossentropy()\n",
        "        # Structural Similarity Index value.\n",
        "        self.ssim_value = tf.image.ssim\n",
        "        #  Jaccard / IoU loss.\n",
        "        self.iou_value = self.calculate_iou\n",
        "\n",
        "    def calculate_iou(\n",
        "        self,\n",
        "        y_true,\n",
        "        y_pred,\n",
        "    ):\n",
        "        \"\"\"Calculate intersection over union (IoU) between images.\"\"\"\n",
        "        intersection = backend.sum(backend.abs(y_true * y_pred), axis=[1, 2, 3])\n",
        "        union = backend.sum(y_true, [1, 2, 3]) + backend.sum(y_pred, [1, 2, 3])\n",
        "        union = union - intersection\n",
        "        return backend.mean(\n",
        "            (intersection + self.smooth) / (union + self.smooth), axis=0\n",
        "        )\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        cross_entropy_loss = self.cross_entropy_loss(y_true, y_pred)\n",
        "\n",
        "        ssim_value = self.ssim_value(y_true, y_pred, max_val=1)\n",
        "        ssim_loss = backend.mean(1 - ssim_value + self.smooth, axis=0)\n",
        "\n",
        "        iou_value = self.iou_value(y_true, y_pred)\n",
        "        iou_loss = 1 - iou_value\n",
        "\n",
        "        # Add all three losses.\n",
        "        return cross_entropy_loss + ssim_loss + iou_loss\n",
        "\n",
        "\n",
        "basnet_model = basnet(\n",
        "    input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3], out_classes=OUT_CLASSES\n",
        ")  # Create model.\n",
        "basnet_model.summary()  # Show model summary.\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-4, epsilon=1e-8)\n",
        "# Compile model.\n",
        "basnet_model.compile(\n",
        "    loss=BasnetLoss(),\n",
        "    optimizer=optimizer,\n",
        "    metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDBD33pdWNp3",
        "outputId": "f6d86a0c-68b2-4f86-aebd-433c7aee246b"
      },
      "outputs": [],
      "source": [
        "basnet_model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkhWA4lEWQTc",
        "outputId": "8e46b359-9053-499a-ce16-98d1942407b9"
      },
      "outputs": [],
      "source": [
        "!!gdown 1OWKouuAQ7XpXZbWA3mmxDPrFGW71Axrg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "jL49703-WSBU",
        "outputId": "b746d623-0d14-4ceb-b82d-2df406a15110"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i + 1)\n",
        "        plt.title(title[i])\n",
        "        if i == 2:  # Predicted Mask\n",
        "            plt.imshow(display_list[i].squeeze(), cmap=\"gray\")\n",
        "            print(\"Prediction Stats - Min:\", np.min(display_list[i]), \"Max:\", np.max(display_list[i]))\n",
        "        else:\n",
        "            plt.imshow(keras.utils.array_to_img(display_list[i]), cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "for image, mask in val_dataset.take(1):\n",
        "    prediction = basnet_model.predict(image)  # Assuming you have a prediction step\n",
        "    display([image[0], mask[0], prediction[0]])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
