{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxK4aYi_h9zw"
      },
      "source": [
        "# Simple U-Net Xception-style model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULadYaIQiFHw"
      },
      "source": [
        "## Load Dataset\n",
        "The dataset is composed of cropped and augmented images from the original provided dataset. The structure is\n",
        "- \\results\n",
        "  - \\images\n",
        "      - img_(n).tif\n",
        "  - \\masks\n",
        "      - img(n).png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HRA5iLmO_dH",
        "outputId": "8b2dbd36-2ed8-4925-db25-294f7917d4ec"
      },
      "outputs": [],
      "source": [
        "!unzip results.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVU3co8LimCN"
      },
      "source": [
        "### Importing required libraries\n",
        "We will be using cv2 for image processing and matplotlib for visualization of the results.\n",
        "For training the model, keras and tensorflow will be used.\n",
        "Numpy will be used for numerical operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iOuB9w3QQM3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNo3LBLVi40F"
      },
      "source": [
        "## Load Images\n",
        "The images are then loaded by using OpenCV imread method.\n",
        "Tests were conducted by using keras load_image method but it was not compatible with .Tif images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QupGLybsjGDN"
      },
      "source": [
        "### Parameters\n",
        "- Input dir = input folder (images)\n",
        "- Target dir = target / annotations folder (masks)\n",
        "- Img_size = image resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIiOnMBsjUop"
      },
      "outputs": [],
      "source": [
        "input_dir = \"./results/images\"\n",
        "target_dir = \"./results/masks\"\n",
        "img_size = (128,128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DtBiaLLja-d"
      },
      "source": [
        "### Listing image paths\n",
        "Paths are mapped according to the image and mask names, sorted by their ids and stored in a list.\n",
        "The lists are latter used to load the images and masks as numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxHEmo8aQUXD"
      },
      "outputs": [],
      "source": [
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "        if fname.endswith(\".tif\")\n",
        "    ],\n",
        "    key = lambda x:  x.split(\"_\")[1].split(\".\")[0]\n",
        ")\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir, fname)\n",
        "        for fname in os.listdir(target_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ],\n",
        "    key = lambda x: x.split(\"_\")[1].split(\".\")[0]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Integrity Check\n",
        "Before proceeding, the integrity of the dataset is checked by comparing the number of images and masks along with their names from the lists.\n",
        "Each display line should have the same image and mask name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVTV3DUAQvfN",
        "outputId": "5ab32f8e-a921-46ba-b33d-587adf72c939"
      },
      "outputs": [],
      "source": [
        "print(\"Number of inputs:\", len(input_img_paths))\n",
        "print(\"Number of labels:\", len(target_img_paths))\n",
        "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
        "    print(input_path, \"|\", target_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZdijz4Bjmxi"
      },
      "source": [
        "## Loading image arrays from paths\n",
        "Here we use the cv2 imread method to load the images from the listed paths. Following this operation the images can be easily converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_img_paths_cv2 = [cv2.imread(path) for path in input_img_paths]\n",
        "target_img_paths_cv2 = [cv2.imread(path, cv2.IMREAD_GRAYSCALE) for path in target_img_paths]\n",
        "\n",
        "for i in range(10):\n",
        "    cv2_imshow(input_img_paths_cv2[i])\n",
        "    cv2_imshow(target_img_paths_cv2[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f_2gumnjxJ8"
      },
      "source": [
        "## Convert Img object to numpy array\n",
        "For further processing, the images are converted to numpy arrays. This ensures that the images can be used for training the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnKmQD6X67M8"
      },
      "outputs": [],
      "source": [
        "input_imgs_np = [(np.asarray(img) / 255).astype(np.float32) for img in input_img_paths_cv2]\n",
        "target_imgs_np = [np.expand_dims((np.asarray(img) / 255).astype(np.uint8), axis=-1) for img in target_img_paths_cv2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9baWYE1dj4uN"
      },
      "source": [
        "## Create Tensorflow Batch Dataset\n",
        "Now that the images and masks are loaded, we can create a tensorflow dataset from the numpy arrays. This will allow us to use the dataset for training the model later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce3j3n3R3wqI"
      },
      "outputs": [],
      "source": [
        "def get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    input_img_arr,\n",
        "    target_img_arr,\n",
        "    max_dataset_len=None,\n",
        "):\n",
        "    \"\"\"Returns a TF Dataset.\"\"\"\n",
        "\n",
        "    if max_dataset_len:\n",
        "        input_img_arr = input_img_arr[:max_dataset_len]\n",
        "        target_img_arr = target_img_arr[:max_dataset_len]\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((input_img_arr, target_img_arr))\n",
        "    return dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFiI8aQEkUK-"
      },
      "source": [
        "### Define training / test / validation Datasets\n",
        "Instead of using the entire dataset for training, we can split the dataset into training, testing and validation datasets. This is done by divinding the original numpy arrays into 2 parts, one for training and the other for testing and validation. To ensure proper shuffling of the separated numpy arrays, we are setting a fixed seed value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwbgHaPf4hMW"
      },
      "outputs": [],
      "source": [
        "val_percent = 0.25 # Percentage of the data to be used for validation\n",
        "\n",
        "val_samples = int(len(input_imgs_np) * val_percent)\n",
        "random.Random(800).shuffle(input_imgs_np)\n",
        "random.Random(800).shuffle(target_imgs_np)\n",
        "\n",
        "train_input_img_sample = input_imgs_np[:-val_samples]\n",
        "train_target_img_sample = target_imgs_np[:-val_samples]\n",
        "val_input_img_sample = input_imgs_np[-val_samples:]\n",
        "val_target_img_sample = target_imgs_np[-val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNSq-Eeqkhgu"
      },
      "source": [
        "#### Verify Shapes\n",
        "The shapes of the training, testing and validation samples are verified to ensure that the data is divided correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcl4UwMnANtW",
        "outputId": "e7a56d18-e109-452c-f74c-2faee96cc160"
      },
      "outputs": [],
      "source": [
        "print(\"Train Shapes\")\n",
        "print(train_input_img_sample[0].shape)\n",
        "print(train_target_img_sample[0].shape)\n",
        "\n",
        "print(\"Evaluation Shapes\")\n",
        "print(val_input_img_sample[0].shape)\n",
        "print(val_target_img_sample[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parameters\n",
        "- Batch size = number of images to be processed in one go\n",
        "- num_classes = number of classes in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 1 # Number of classes in the model\n",
        "batch_size = 2 # Batch size for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Datasets\n",
        "The actual tensorflow batch datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBX4zUz-4qcf"
      },
      "outputs": [],
      "source": [
        "# training dataset\n",
        "train_dataset = get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    train_input_img_sample,\n",
        "    train_target_img_sample,\n",
        "    max_dataset_len=2000,\n",
        ")\n",
        "\n",
        "# validation dataset\n",
        "valid_dataset = get_dataset(\n",
        "    batch_size, img_size, val_input_img_sample, val_target_img_sample\n",
        ")\n",
        "\n",
        "# evaluation dataset\n",
        "eval = get_dataset(\n",
        "    batch_size, img_size, val_input_img_sample, val_target_img_sample\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRz-W95slgFx"
      },
      "source": [
        "# Model\n",
        "Here we define the CNN model. The base architecture was based on Keras examples for image segmentation, and modified to fit our data requirements and binary segmentation. https://keras.io/examples/vision/oxford_pets_image_segmentation/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW_T9ws144Ze",
        "outputId": "c2b3d6fe-d6c0-490e-9c04-ad91bf2fe634"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, (1,1), activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model\n",
        "model = get_model(img_size, num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Function\n",
        "The loss function is defined as binary crossentropy. This is a common loss function used for binary classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF8dS5M854iQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer, loss=loss, metrics=[keras.metrics.BinaryAccuracy()]\n",
        ")\n",
        "\n",
        "# Callback defined to save the best model during training\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"plot_segmentation.keras\", save_best_only=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quJoAwZ-mDBc"
      },
      "source": [
        "## Training\n",
        "The model is trained using the training dataset. The number of epochs can be adjusted to improve the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90bijna06EIh",
        "outputId": "cccc6058-1bd9-4ada-b255-3ed9a1863c45"
      },
      "outputs": [],
      "source": [
        "epochs = 50 # Number of epochs for training\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1OTZkcZmF7L"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMPMQ69-mH5q"
      },
      "source": [
        "## Testing Predictions\n",
        "The model is tested on the test dataset to generate predictions. The predictions are then visualized to evaluate the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT-t7QTzmKDR",
        "outputId": "abe9ebcf-6aaf-49ab-b2e0-10c965094071"
      },
      "outputs": [],
      "source": [
        "test_preds = model.predict(valid_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTg5EZHmKkR"
      },
      "source": [
        "### Displaying the Results\n",
        "The original image, mask and predicted mask are displayed side by side for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "SLtDcC9pILU_",
        "outputId": "b2e82b91-5a23-44de-cc07-7602393353fe"
      },
      "outputs": [],
      "source": [
        "for idx, (input, label) in enumerate(valid_dataset.unbatch()):\n",
        "  f, axarr = plt.subplots(1,3)\n",
        "  axarr[0].imshow(input)\n",
        "  axarr[1].imshow(label.numpy()*255)\n",
        "  axarr[2].imshow(test_preds[idx]*255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldfF8AH2otSy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
