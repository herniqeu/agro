{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNDHtz9R2v4C"
      },
      "source": [
        "# Initial CNN Implementation [DRAFT]\n",
        "Draft of the initial implementation of the CNN model for the Group's project. Created with the objective of understanding the basic structure of the model and its implementation in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi4rF6LY26VD"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lTFfDIY2_LG"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK0Pa2tN24cJ",
        "outputId": "3390cc4b-b464-428c-c0b3-eefab988b8a8"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly_ns5BF3AvH"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rX0lmfC3Ccn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSi2oWyn3EAm"
      },
      "source": [
        "# Auxiliary Functions and Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duAYj3n13KNu"
      },
      "outputs": [],
      "source": [
        "# Add here all auxiliary functions (dataset split methods, formatting and conversion methods...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 3: Image Processing Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing Pipeline Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `ProcessingPipeline` class orchestrates the application of \n",
        "\n",
        "*   Item da lista\n",
        "*   Item da lista\n",
        "\n",
        "filters and augmentations to the image data. It automates the process of image enhancement and prepares the data for segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProcessingPipeline:\n",
        "    \"\"\"\n",
        "    Manages the application of image processing filters and augmentations.\n",
        "\n",
        "    Attributes:\n",
        "        filters (list): A list of filter objects to apply to the images.\n",
        "        augmentations (list): A list of augmentation objects to apply to the images.\n",
        "        history (list): Records outcomes of applied filters and augmentations for visualization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, plot_storyline=False):\n",
        "        \"\"\"\n",
        "        Initializes the processing pipeline with empty lists for filters, augmentations, and history.\n",
        "        \"\"\"\n",
        "        self.filters = []\n",
        "        self.augmentations = []\n",
        "        self.history = []\n",
        "\n",
        "    def add_filters(self, filters):\n",
        "        \"\"\"\n",
        "        Adds multiple filter objects to the pipeline.\n",
        "\n",
        "        Parameters:\n",
        "            filters (list): List of filter objects to be added.\n",
        "        \"\"\"\n",
        "        self.filters.extend(filters)\n",
        "\n",
        "    def clear_filters(self):\n",
        "        \"\"\"\n",
        "        Clears all filter objects from the pipeline.\n",
        "        \"\"\"\n",
        "        self.filters = []\n",
        "\n",
        "    def add_augmentations(self, augmentations):\n",
        "        \"\"\"\n",
        "        Adds multiple augmentation objects to the pipeline.\n",
        "\n",
        "        Parameters:\n",
        "            augmentations (list): List of augmentation objects to be added.\n",
        "        \"\"\"\n",
        "        self.augmentations.extend(augmentations)\n",
        "\n",
        "    def clear_augmentations(self):\n",
        "        \"\"\"\n",
        "        Clears all augmentation objects from the pipeline.\n",
        "        \"\"\"\n",
        "        self.augmentations = []\n",
        "\n",
        "    def apply_filters(self, img):\n",
        "        \"\"\"\n",
        "        Applies each filter in sequence to the image.\n",
        "\n",
        "        Parameters:\n",
        "            img (numpy.ndarray): The original image to be processed.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: The image processed by all filters.\n",
        "        \"\"\"\n",
        "        _img = img\n",
        "        for _filter in self.filters:\n",
        "            _img, _ = _filter.apply(_img, None)\n",
        "            self.history.append((_img.copy(), type(_filter).__name__, \"Filter\"))\n",
        "        return _img\n",
        "\n",
        "    def apply_crop(self, img, mask, new_width=120, new_height=120, n=3):\n",
        "        \"\"\"\n",
        "        Randomly crops the given image and mask arrays into 'n' new images and masks with dimensions 'new_width' x 'new_height'.\n",
        "\n",
        "        Parameters:\n",
        "            img (numpy.ndarray): The numpy array representing the original image.\n",
        "            mask (numpy.ndarray): The numpy array representing the original mask.\n",
        "            n (int): The number of new images and masks to generate.\n",
        "            new_width (int): The width of the new images and masks.\n",
        "            new_height (int): The height of the new images and masks.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing three elements:\n",
        "                   - A list of numpy.ndarray representing the cropped images.\n",
        "                   - A list of numpy.ndarray representing the cropped masks.\n",
        "                   - A list of tuples containing the top-left corner coordinates of each cropped area.\n",
        "        \"\"\"\n",
        "        original_height, original_width = img.shape[:2]\n",
        "        if new_width > original_width or new_height > original_height:\n",
        "            print(original_width)\n",
        "            raise ValueError(\n",
        "                \"New dimensions must be smaller than the original dimensions.\"\n",
        "            )\n",
        "\n",
        "        cropped_images, cropped_masks, crop_coordinates = [], [], []\n",
        "        for _ in range(n):\n",
        "            top = np.random.randint(0, original_height - new_height + 1)\n",
        "            left = np.random.randint(0, original_width - new_width + 1)\n",
        "            crop_slice = np.s_[top : top + new_height, left : left + new_width]\n",
        "            cropped_images.append(img[crop_slice])\n",
        "            cropped_masks.append(mask[crop_slice])\n",
        "            crop_coordinates.append((left, top))\n",
        "            self.history.append(\n",
        "                (img[crop_slice], f\"Cropped Image at ({left}, {top})\", \"Crop\")\n",
        "            )\n",
        "\n",
        "        return cropped_images, cropped_masks, crop_coordinates\n",
        "\n",
        "    def apply_augmentations(self, images, masks, n=3):\n",
        "        \"\"\"\n",
        "        Applies data augmentation to a list of images and their corresponding masks.\n",
        "\n",
        "        Parameters:\n",
        "            images (list of numpy.ndarray): The list of numpy arrays representing the original images.\n",
        "            masks (list of numpy.ndarray): The list of numpy arrays representing the masks for the images.\n",
        "            n (int): Number of augmentations to apply to each image.\n",
        "            filters (list): List of instantiated filter classes to apply.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing two elements:\n",
        "                   - List of numpy.ndarray representing the original and augmented images.\n",
        "                   - List of numpy.ndarray representing the original and augmented masks.\n",
        "        \"\"\"\n",
        "        all_images = []\n",
        "        all_masks = []\n",
        "\n",
        "        for image, mask in zip(images, masks):\n",
        "            augmented_images = [image]\n",
        "            augmented_masks = [mask]\n",
        "            previous_transformations = set()\n",
        "\n",
        "            while len(augmented_images) - 1 < n:\n",
        "                selected_filter = random.choice(self.augmentations)\n",
        "                transformation_key = (\n",
        "                    type(selected_filter).__name__,\n",
        "                    tuple(selected_filter.__dict__.values()),\n",
        "                )\n",
        "\n",
        "                if transformation_key not in previous_transformations:\n",
        "                    augmented_image, augmented_mask = selected_filter.apply(image, mask)\n",
        "                    augmented_images.append(augmented_image)\n",
        "                    augmented_masks.append(augmented_mask)\n",
        "                    previous_transformations.add(transformation_key)\n",
        "                    self.history.append(\n",
        "                        (\n",
        "                            augmented_image,\n",
        "                            f\"Augmented with {type(selected_filter).__name__}\",\n",
        "                            \"Augmentation\",\n",
        "                        )\n",
        "                    )\n",
        "                    self.history.append(\n",
        "                        (\n",
        "                            augmented_mask,\n",
        "                            f\"[MASK] Augmented with {type(selected_filter).__name__}\",\n",
        "                            \"Augmentation\",\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            all_images.extend(augmented_images)\n",
        "            all_masks.extend(augmented_masks)\n",
        "\n",
        "        return all_images, all_masks\n",
        "\n",
        "    def apply_normalization(self, imgs, masks):\n",
        "        \"\"\"\n",
        "        Normalizes the pixel values of images and masks to the range [0, 1].\n",
        "\n",
        "        Parameters:\n",
        "            imgs (list of numpy.ndarray): The list of images to be normalized.\n",
        "            masks (list of numpy.ndarray): The list of masks to be normalized.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing two elements:\n",
        "                   - List of numpy.ndarray representing the normalized images.\n",
        "                   - List of numpy.ndarray representing the normalized masks.\n",
        "        \"\"\"\n",
        "        _imgs = []\n",
        "        _masks = []\n",
        "        for index, _img in enumerate(imgs):\n",
        "            height, width, _ = _img.shape\n",
        "            m_height, m_width, _ = masks[index].shape\n",
        "            norm_img = np.zeros((height, width))\n",
        "            norm_mask = np.zeros((m_height, m_width))\n",
        "            norm_img = cv.normalize(_img, norm_img, 0, 255, cv.NORM_MINMAX)\n",
        "            norm_mask = cv.normalize(masks[index], norm_mask, 0, 255, cv.NORM_MINMAX)\n",
        "            norm_img = norm_img / 255\n",
        "            norm_mask = norm_mask / 255\n",
        "            _imgs.append(norm_img)\n",
        "            _masks.append(norm_mask)\n",
        "        return _imgs, _masks\n",
        "\n",
        "    def run(self, img, mask, n_augmented, crop_size=120, n_crop=20):\n",
        "        \"\"\"\n",
        "        Executes the entire image processing pipeline.\n",
        "\n",
        "        Parameters:\n",
        "            img (numpy.ndarray): The original image to process.\n",
        "            mask (numpy.ndarray): The associated mask for the image.\n",
        "            n_augmented (int): The number of augmented images to generate.\n",
        "            crop_size (int): The size for cropping the images.\n",
        "            n_crop (int): The number of crops to produce.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing three elements:\n",
        "                   - List of numpy.ndarray representing the normalized images.\n",
        "                   - List of numpy.ndarray representing the normalized masks.\n",
        "                   - List of tuples containing the coordinates of cropped areas.\n",
        "        \"\"\"\n",
        "        highlighted_img = self.apply_filters(img)\n",
        "        cropped_imgs, cropped_masks, cropped_coordinates = self.apply_crop(\n",
        "            highlighted_img, mask, new_height=crop_size, new_width=crop_size, n=n_crop\n",
        "        )\n",
        "        augmented_imgs, augmented_masks = self.apply_augmentations(\n",
        "            cropped_imgs, cropped_masks, n_augmented\n",
        "        )\n",
        "        normalized_imgs, normalized_masks = self.apply_normalization(\n",
        "            augmented_imgs, augmented_masks\n",
        "        )\n",
        "        return normalized_imgs, normalized_masks, cropped_coordinates\n",
        "\n",
        "    def get_history(self):\n",
        "        return self.history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Processors\n",
        "\n",
        "Here we define a suite of image processing classes that extend `BaseImageProcess`. Each class implements a specific image processing technique, such as rotation, blurring, and thresholding, which are essential for the feature extraction phase of plot segmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseImageProcess:\n",
        "    \"\"\"\n",
        "    BaseImageProcess: A base class for image processing algorithms.\n",
        "\n",
        "    This class provides a basic framework for implementing image processing algorithms and is intended to be subclassed.\n",
        "    Subclasses should implement the `apply` method to perform specific image processing operations on an input image.\n",
        "    \"\"\"\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        \"\"\"\n",
        "        Placeholder for applying an image processing algorithm.\n",
        "\n",
        "        Args:\n",
        "            img: The input image to process.\n",
        "\n",
        "        Returns:\n",
        "            The processed image.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class Rotate(BaseImageProcess):\n",
        "    def __init__(self):\n",
        "        self.angle = random.choice([-15, -10, -5, 5, 10, 15])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        height, width = img.shape[:2]\n",
        "        rotation_matrix = cv.getRotationMatrix2D((width / 2, height / 2), self.angle, 1)\n",
        "        return cv.warpAffine(img, rotation_matrix, (width, height)), (\n",
        "            cv.warpAffine(mask, rotation_matrix, (width, height))\n",
        "            if mask is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "\n",
        "class BilateralFilter(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    BilateralFilter: Applies bilateral filtering to an image to reduce noise while keeping edges sharp.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d=9, sigmaColor=75, sigmaSpace=75):\n",
        "        self.d = d\n",
        "        self.sigmaColor = sigmaColor\n",
        "        self.sigmaSpace = sigmaSpace\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.bilateralFilter(img, self.d, self.sigmaColor, self.sigmaSpace), mask\n",
        "\n",
        "\n",
        "class Translate(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Applies translation to an image using random horizontal and vertical shifts.\n",
        "\n",
        "    Attributes:\n",
        "        dx (int): Horizontal shift, chosen randomly from a specified range.\n",
        "        dy (int): Vertical shift, chosen randomly from a specified range.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dx = random.choice([-10, -5, 0, 5, 10])\n",
        "        self.dy = random.choice([-10, -5, 0, 5, 10])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        translation_matrix = np.float32([[1, 0, self.dx], [0, 1, self.dy]])\n",
        "        height, width = img.shape[:2]\n",
        "        return cv.warpAffine(img, translation_matrix, (width, height)), (\n",
        "            cv.warpAffine(mask, translation_matrix, (width, height))\n",
        "            if mask is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "\n",
        "class Flip(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Flips an image either horizontally, vertically, or both, based on a randomly selected flip type.\n",
        "\n",
        "    Attributes:\n",
        "        flip_type (int): Type of flip to apply; -1 for both axes, 0 for vertical, 1 for horizontal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.flip_type = random.choice([-1, 0, 1])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.flip(img, self.flip_type), (\n",
        "            cv.flip(mask, self.flip_type) if mask is not None else None\n",
        "        )\n",
        "\n",
        "\n",
        "class BrightnessContrast(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Adjusts the brightness and contrast of an image using random values.\n",
        "\n",
        "    Attributes:\n",
        "        alpha (float): Factor by which the contrast will be adjusted.\n",
        "        beta (int): Value that will be added to the pixels for brightness adjustment.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.alpha = random.uniform(0.5, 1.5)\n",
        "        self.beta = random.randint(-50, 50)\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.convertScaleAbs(img, alpha=self.alpha, beta=self.beta), mask\n",
        "\n",
        "\n",
        "class MedianBlur(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Applies median blurring to an image using a randomly chosen kernel size.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): The size of the kernel used, selected randomly from a set of possible odd sizes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.kernel_size = random.choice([3, 5, 7, 9, 11])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.medianBlur(img, self.kernel_size), mask\n",
        "\n",
        "\n",
        "class RandomGaussianBlur(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    Applies Gaussian blur filtering to an image with a randomly chosen kernel size.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the Gaussian blur kernel, selected randomly.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.kernel_size = random.choice([3, 5, 7, 9, 11])\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.GaussianBlur(img, (self.kernel_size, self.kernel_size), 0), mask\n",
        "\n",
        "\n",
        "class GaussianBlur(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    GaussianBlur: Applies Gaussian blur filtering to an image.\n",
        "\n",
        "    This class provides an implementation of Gaussian blur filtering, commonly used to reduce image noise and detail.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the kernel used for the Gaussian filter.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size=5):\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.GaussianBlur(img, (self.kernel_size, self.kernel_size), 0), mask\n",
        "\n",
        "\n",
        "class BinaryThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    BinaryThresh: Applies binary thresholding to an image.\n",
        "\n",
        "    Binary thresholding converts an image to binary (black and white) based on a threshold value. Pixels above the\n",
        "    threshold are set to the maximum value, and those below are set to zero.\n",
        "\n",
        "    Attributes:\n",
        "        thresh (int): Threshold value.\n",
        "        max_val (int): Maximum value to use with the threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresh=127, max_val=255):\n",
        "        self.thresh = thresh\n",
        "        self.max_val = max_val\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        _, _img = cv.threshold(_img, self.thresh, self.max_val, cv.THRESH_BINARY)\n",
        "        return _img, mask\n",
        "\n",
        "\n",
        "class AdaptiveMeanThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    AdaptiveMeanThresh: Applies adaptive mean thresholding to an image.\n",
        "\n",
        "    Unlike simple thresholding, adaptive thresholding changes the threshold dynamically over the image based on local\n",
        "    image characteristics.\n",
        "\n",
        "    Attributes:\n",
        "        block_size (int): Size of a pixel neighborhood used to calculate the threshold.\n",
        "        c (int): Constant subtracted from the calculated mean or weighted mean.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, block_size=11, c=2):\n",
        "        self.block_size = block_size\n",
        "        self.c = c\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        return (\n",
        "            cv.adaptiveThreshold(\n",
        "                _img,\n",
        "                255,\n",
        "                cv.ADAPTIVE_THRESH_MEAN_C,\n",
        "                cv.THRESH_BINARY,\n",
        "                self.block_size,\n",
        "                self.c,\n",
        "            ),\n",
        "            mask,\n",
        "        )\n",
        "\n",
        "\n",
        "class AdaptiveGaussThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    AdaptiveGaussThresh: Applies adaptive Gaussian thresholding to an image.\n",
        "\n",
        "    This method uses a weighted sum of neighbourhood values where weights are a Gaussian window, which provides\n",
        "    a more natural thresholding, especially under varying illumination.\n",
        "\n",
        "    Attributes:\n",
        "        block_size (int): Size of a pixel neighborhood used to calculate the threshold.\n",
        "        c (int): Constant subtracted from the calculated weighted sum.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, block_size=11, c=2):\n",
        "        self.block_size = block_size\n",
        "        self.c = c\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        return (\n",
        "            cv.adaptiveThreshold(\n",
        "                _img,\n",
        "                255,\n",
        "                cv.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                cv.THRESH_BINARY,\n",
        "                self.block_size,\n",
        "                self.c,\n",
        "            ),\n",
        "            mask,\n",
        "        )\n",
        "\n",
        "\n",
        "class OtsuThresh(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    OtsuThresh: Applies Otsu's thresholding to automatically perform histogram shape-based image thresholding.\n",
        "\n",
        "    This method is useful when the image contains two prominent pixel intensities and calculates an optimal threshold\n",
        "    separating these two classes so that their combined spread (intra-class variance) is minimal.\n",
        "    \"\"\"\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        _img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) if len(img.shape) > 2 else img\n",
        "        _, _img = cv.threshold(_img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
        "        return _img, mask\n",
        "\n",
        "\n",
        "class MorphDilate(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    MorphDilate: Applies morphological dilation to an image.\n",
        "\n",
        "    Dilation increases the white region in the image or size of the foreground object. Commonly used to accentuate\n",
        "    features.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the structuring element.\n",
        "        iterations (int): Number of times dilation is applied.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size=3, iterations=2):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.iterations = iterations\n",
        "        self.kernel = np.ones((self.kernel_size, self.kernel_size), np.uint8)\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.dilate(img, self.kernel, iterations=self.iterations), mask\n",
        "\n",
        "\n",
        "class MorphErode(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    MorphErode: Applies morphological erosion to an image.\n",
        "\n",
        "    Erosion erodes away the boundaries of the foreground object and is used to diminish the features of an image.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): Size of the structuring element.\n",
        "        iterations (int): Number of times erosion is applied.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size=3, iterations=2):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.iterations = iterations\n",
        "        self.kernel = np.ones((self.kernel_size, self.kernel_size), np.uint8)\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        return cv.erode(img, self.kernel, iterations=self.iterations), mask\n",
        "\n",
        "\n",
        "class LoG(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    LoG: Applies Laplacian of Gaussian filtering to an image.\n",
        "\n",
        "    This method is used to highlight regions of rapid intensity change and is therefore often used for edge detection.\n",
        "    First, it applies a Gaussian blur, then computes the Laplacian of the result.\n",
        "\n",
        "    Attributes:\n",
        "        sigma (float): Standard deviation of the Gaussian filter.\n",
        "        size (int): Size of the filter kernel.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sigma=2.0, size=None):\n",
        "        self.sigma = sigma\n",
        "        self.size = (\n",
        "            size\n",
        "            if size is not None\n",
        "            else int(6 * self.sigma + 1) if self.sigma >= 1 else 7\n",
        "        )\n",
        "        if self.size % 2 == 0:\n",
        "            self.size += 1\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        x, y = np.meshgrid(\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "        )\n",
        "        kernel = (\n",
        "            -(1 / (np.pi * self.sigma**4))\n",
        "            * (1 - ((x**2 + y**2) / (2 * self.sigma**2)))\n",
        "            * np.exp(-(x**2 + y**2) / (2 * self.sigma**2))\n",
        "        )\n",
        "        kernel = kernel / np.sum(np.abs(kernel))\n",
        "        return cv.filter2D(img, -1, kernel), mask\n",
        "\n",
        "\n",
        "class LoGConv(BaseImageProcess):\n",
        "    \"\"\"\n",
        "    LoGConv: Implements convolution with a Laplacian of Gaussian kernel to an image.\n",
        "\n",
        "    Similar to the LoG class, but tailored for applying custom convolution operations directly with a manually\n",
        "    crafted LoG kernel.\n",
        "\n",
        "    Attributes:\n",
        "        sigma (float): Standard deviation of the Gaussian filter.\n",
        "        size (int): Size of the filter kernel.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sigma=2.0, size=None):\n",
        "        self.sigma = sigma\n",
        "        self.size = size if size is not None else int(6 * sigma + 1)\n",
        "        if self.size % 2 == 0:\n",
        "            self.size += 1\n",
        "\n",
        "    def apply(self, img, mask=None):\n",
        "        if len(img.shape) == 3:\n",
        "            img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        x, y = np.meshgrid(\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "            np.arange(-self.size // 2 + 1, self.size // 2 + 1),\n",
        "        )\n",
        "        kernel = (\n",
        "            -(1 / (np.pi * self.sigma**4))\n",
        "            * (1 - ((x**2 + y**2) / (2 * self.sigma**2)))\n",
        "            * np.exp(-(x**2 + y**2) / (2 * self.sigma**2))\n",
        "        )\n",
        "        kernel = kernel / np.sum(np.abs(kernel))\n",
        "        if len(img.shape) == 3:\n",
        "            img = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
        "            img = convolve(img, kernel)\n",
        "            img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "        else:\n",
        "            img = convolve(img, kernel)\n",
        "        return img, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 4: Auxiliary Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n",
        "\n",
        "Auxiliary functions such as `load_image` and `display_history` are defined here. These functions support the main pipeline by providing image loading capabilities and visualizing the processing history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_image(path, color_mode=cv.IMREAD_COLOR):\n",
        "    \"\"\"Loads an image from the given path with specified color mode.\"\"\"\n",
        "    image = cv.imread(path, color_mode)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Could not load image from {path}\")\n",
        "    return image\n",
        "\n",
        "def display_history(history):\n",
        "    n_images = len(history)\n",
        "    n_rows = math.ceil(n_images ** 0.5)\n",
        "    n_cols = math.ceil(n_images / n_rows)\n",
        "    plt.figure(figsize=(n_cols * 4, n_rows * 4))\n",
        "    for i, (img, label, _) in enumerate(history):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def get_dataset(batch_size,\n",
        "    img_size,\n",
        "    input_img_arr,\n",
        "    target_img_arr,\n",
        "    max_dataset_len=None,\n",
        "):\n",
        "    \"\"\"Returns a TF Dataset.\"\"\"\n",
        "    if max_dataset_len:\n",
        "        input_img_arr = input_img_arr[:max_dataset_len]\n",
        "        target_img_arr = target_img_arr[:max_dataset_len]\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((input_img_arr, target_img_arr))\n",
        "    return dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 5: Execution of Processing Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Configuration\n",
        "\n",
        "Set up the processing pipeline by selecting the desired filters and augmentations. This configuration will determine how the images are processed and enhanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_augmented = 5\n",
        "filters = []\n",
        "augmentations = []\n",
        "augmentations = [Rotate(), Translate(), Flip(), BrightnessContrast(), RandomGaussianBlur(), MedianBlur()]\n",
        "\n",
        "pipeline = ProcessingPipeline()\n",
        "pipeline.add_filters(filters)\n",
        "pipeline.add_augmentations(augmentations)\n",
        "\n",
        "base_masks_path = \"/content/drive/MyDrive/Images/Masks\"\n",
        "base_inputs_path = \"/content/drive/MyDrive/Images/Input\"\n",
        "image_data_manager = ImageDataManager(base_masks_path, base_inputs_path)\n",
        "\n",
        "images_np_array = []\n",
        "masks_np_array = []\n",
        "\n",
        "for key in image_data_manager.objects.keys():\n",
        "  imgs = image_data_manager.objects[key]['images']\n",
        "  imgs_filtered = []\n",
        "\n",
        "  for img in imgs:\n",
        "    if img.shape[1] == 1200:\n",
        "      imgs_filtered.append(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "  image_data_manager.objects[key]['images'] = imgs_filtered\n",
        "  mask = image_data_manager.objects[key]['mask']\n",
        "  image_data_manager.objects[key]['mask'] = mask\n",
        "  img = imgs_filtered[-1]\n",
        "\n",
        "  n_crop = img.shape[0] // 128\n",
        "  imgs, masks, coordinates = pipeline.run(img, mask, crop_size=128, n_crop=n_crop, n_augmented=5)\n",
        "  images_np_array.extend(imgs)\n",
        "  masks_np_array.extend(masks)\n",
        "  \n",
        "\n",
        "count = len(images_np_array)\n",
        "print(f\"Total Image count: {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### History View\n",
        "Views the history of the processing pipeline for a given image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display_history(pipeline.history[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 6 - Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Dataset to Train / Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_samples = int(len(images_np_array) * 0.25)\n",
        "random.Random(800).shuffle(images_np_array)\n",
        "random.Random(800).shuffle(masks_np_array)\n",
        "train_input_img_sample = images_np_array[:-val_samples]\n",
        "train_target_img_sample = masks_np_array[:-val_samples]\n",
        "val_input_img_sample = images_np_array[-val_samples:]\n",
        "val_target_img_sample = masks_np_array[-val_samples:]\n",
        "\n",
        "img_size = (128,128)\n",
        "batch_size = 4\n",
        "\n",
        "# training dataset\n",
        "train_dataset = get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    images_np_array,\n",
        "    masks_np_array,\n",
        "    max_dataset_len=2000,\n",
        ")\n",
        "\n",
        "# validation dataset\n",
        "valid_dataset = get_dataset(\n",
        "    batch_size, img_size, val_input_img_sample, val_target_img_sample\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqxWid2t4Pub"
      },
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbOvCOH64iDO"
      },
      "source": [
        "## Model Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQXQiMHG4kps"
      },
      "outputs": [],
      "source": [
        "epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBmpG-gr4RKt"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkKHQpba4S0c"
      },
      "outputs": [],
      "source": [
        "def xception_model(img_size):\n",
        "    inputs = Input(shape=img_size + (3,))\n",
        "\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x\n",
        "\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        residual = Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual]) \n",
        "        previous_block_activation = x\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = UpSampling2D(2)(x)\n",
        "\n",
        "        residual = UpSampling2D(2)(previous_block_activation)\n",
        "        residual = Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = add([x, residual])\n",
        "        previous_block_activation = x\n",
        "\n",
        "    outputs = Conv2D(1, 3, activation=\"sigmoid\",   padding=\"same\")(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "class LossFunctions:\n",
        "    \"\"\"\n",
        "    A collection of loss functions and corresponding metrics for image segmentation tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def binary_crossentropy():\n",
        "        \"\"\"\n",
        "        Returns the binary cross-entropy loss function configured with from_logits=True.\n",
        "        \n",
        "        Returns:\n",
        "            An instance of tf.keras.losses.BinaryCrossentropy configured with from_logits=True.\n",
        "        \"\"\"\n",
        "        return tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    \n",
        "    def binary_accuracy():\n",
        "        \"\"\"\n",
        "        Returns the binary accuracy metric.\n",
        "\n",
        "        Returns:\n",
        "            An instance of tf.keras.metrics.BinaryAccuracy.\n",
        "        \"\"\"\n",
        "        return tf.keras.metrics.BinaryAccuracy()\n",
        "    \n",
        "    def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "        \"\"\"\n",
        "        Computes the Dice Coefficient, a measure of overlap between true and predicted labels.\n",
        "        \n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            smooth: A smoothing constant to avoid division by zero.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Dice Coefficient.\n",
        "        \"\"\"\n",
        "        y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "    def dice_loss(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Computes the Dice Loss, derived from the Dice Coefficient, used to maximize overlap.\n",
        "        \n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Dice Loss.\n",
        "        \"\"\"\n",
        "        return 1 - LossFunctions.dice_coefficient(y_true, y_pred)\n",
        "    \n",
        "    def jaccard_index(y_true, y_pred, smooth=1):\n",
        "        \"\"\"\n",
        "        Computes the Jaccard Index, also known as Intersection over Union (IoU), \n",
        "        which measures the overlap between true and predicted labels.\n",
        "        \n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            smooth: A smoothing constant to avoid division by zero.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Jaccard Index.\n",
        "        \"\"\"\n",
        "        y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        sum_ = K.sum(y_true_f) + K.sum(y_pred_f)\n",
        "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "        return jac\n",
        "    \n",
        "    def jaccard_loss(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Computes the Jaccard Loss, derived from the Jaccard Index, used to maximize \n",
        "        the intersection over union.\n",
        "\n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Jaccard Loss.\n",
        "        \"\"\"\n",
        "        return 1 - LossFunctions.jaccard_index(y_true, y_pred)\n",
        "    \n",
        "    def tversky_index(y_true, y_pred, alpha=0.5, beta=0.5, smooth=1):\n",
        "        \"\"\"\n",
        "        Computes the Tversky Index, a generalized form of the Dice Coefficient, \n",
        "        that introduces a weighting between false positives and false negatives.\n",
        "        \n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            alpha: Weight for false negatives.\n",
        "            beta: Weight for false positives.\n",
        "            smooth: A smoothing constant to avoid division by zero.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Tversky Index.\n",
        "        \"\"\"\n",
        "        y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        true_pos = K.sum(y_true_f * y_pred_f)\n",
        "        false_neg = K.sum(y_true_f * (1 - y_pred_f))\n",
        "        false_pos = K.sum((1 - y_true_f) * y_pred_f)\n",
        "        return (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
        "    \n",
        "    def tversky_loss(y_true, y_pred, alpha=0.5, beta=0.5):\n",
        "        \"\"\"\n",
        "        Computes the Tversky Loss, derived from the Tversky Index, used to handle \n",
        "        class imbalance by adjusting the penalty for false positives and false negatives.\n",
        "        \n",
        "        Args:\n",
        "            y_true: Ground truth labels.\n",
        "            y_pred: Predicted labels.\n",
        "            alpha: Weight for false negatives.\n",
        "            beta: Weight for false positives.\n",
        "\n",
        "        Returns:\n",
        "            A tensor representing the Tversky Loss.\n",
        "        \"\"\"\n",
        "        return 1 - LossFunctions.tversky_index(y_true, y_pred, alpha, beta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Usage Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para `binary_crossentropy`:\n",
        "\n",
        "```\n",
        "model.compile(optimizer='adam', \n",
        "              loss=LossFunctions.binary_crossentropy(), \n",
        "              metrics=[LossFunctions.binary_accuracy()])\n",
        "```\n",
        "\n",
        "Para `dice_loss`:\n",
        "\n",
        "```\n",
        "model.compile(optimizer=optimizer, \n",
        "              loss=LossFunctions.dice_loss, \n",
        "              metrics=[LossFunctions.dice_coefficient])\n",
        "```\n",
        "\n",
        "\n",
        "Para `jaccard_loss`:\n",
        "\n",
        "```\n",
        "model.compile(optimizer=optimizer, \n",
        "              loss=LossFunctions.jaccard_loss, \n",
        "              metrics=[LossFunctions.jaccard_index])\n",
        "```\n",
        "\n",
        "Para `tversky_loss` (com parâmetros padrão):\n",
        "\n",
        "```\n",
        "model.compile(optimizer=optimizer, \n",
        "              loss=LossFunctions.tversky_loss, \n",
        "              metrics=[LossFunctions.tversky_index])\n",
        "```\n",
        "\n",
        "Para `tversky_loss` com parâmetros específicos:\n",
        "\n",
        "```\n",
        "model.compile(optimizer=optimizer, \n",
        "              loss=lambda y_true, y_pred: LossFunctions.tversky_loss(y_true, y_pred, alpha=0.7, beta=0.3), \n",
        "              metrics=[lambda y_true, y_pred: LossFunctions.tversky_index(y_true, y_pred, alpha=0.7, beta=0.3)])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_size = (128, 128)\n",
        "x_model = xception_model(img_size)\n",
        "\n",
        "x_model.compile(\n",
        "    optimizer=optimizers.Adam(1e-4), loss=\"binary_crossentropy\",\n",
        "    metrics=[K.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "callbks = [\n",
        "    callbacks.ModelCheckpoint(\"x_model.keras\", save_best_only=True)\n",
        "]\n",
        "\n",
        "x_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anP5bj994ocN"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1ytPscH4sAa"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "history = x_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=callbks,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49n5KB7l4vLd"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swTtPWMy4zSv"
      },
      "outputs": [],
      "source": [
        "# show results in this section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsv0jqbb43VH"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQNbCFWZ5BK9"
      },
      "outputs": [],
      "source": [
        "# Implement visualization for predicted outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePS_rvcH5Be3"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJLCfKP25MHw"
      },
      "outputs": [],
      "source": [
        "# Compare metrics and accuracy scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Pd2tQJ5Sby"
      },
      "source": [
        "## Resource Usage Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EdhkPSO5Us3"
      },
      "outputs": [],
      "source": [
        "# A few interesting points here\n",
        "# > Training Time\n",
        "# > Inference Time\n",
        "# > Memory Usage\n",
        "# > Batch Size scalability\n",
        "# > Energy Efficiency (?)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
