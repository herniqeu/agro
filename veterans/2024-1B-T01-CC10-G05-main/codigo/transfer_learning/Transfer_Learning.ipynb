{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementação de Transfer Learning com Arquitetura UNET\n",
        "\n",
        "Nesse notebook, faremos o processo de transfer learning com uma Arquitetura U-Net, extraída do projeto \"Automatic Delineation of Agricultural Fields from Sentinel-2 Images\" da University of Twente\n",
        "\n",
        "O projeto com o modelo que usamos encontra-se disponível nas referências abaixo.\n",
        "\n",
        "## Referências:\n",
        "\n",
        "- Resign M. et al, 2021: Automatic Delineation of Agricultural Fields from Sentinel-2 Images. Disponível em: https://github.com/resingm/field-boundary-delineation/blob/master/paper.pdf. Acesso em 9 de maio de 2024.\n",
        "\n",
        "- Resign M. et al, 2021. Repositório GitHub, acesso em 9 de maio de 2024, https://github.com/resingm/field-boundary-delineation/tree/master\n",
        "\n",
        "## Como executar\n",
        "\n",
        "Para executar esse notebook com CPU ou GPU siga os passos abaixo:\n",
        "1. Baixe este notebook e importe para o <a href=\"https://colab.google/\">Google Colab</a> ou acesse o link: https://colab.research.google.com/drive/1N1qnfT22pUsegvDvoYWfJ_GFZevqfIg6?usp=sharing\n",
        "2. No menu superior direito do colab, onde está escrito \"Conectar\" ou \"Ligar\", clique na seta ao lado e escolha a opção \"Alterar o tipo de ambiente de execução\"\n",
        "3. Uma janela será aberta onde você pode escolher entre utilizar CPU ou GPU. Neste caso, apenas a execução utilizando opção A100 GPU vai funcionar.\n",
        "4. Para rodar este notebook, alguns arquivos são necessários. Acesse https://drive.google.com/drive/folders/1vcymtzjDJqVRd3x0ivSywnouhkqotq5J?usp=sharing e baixe os quatro arquivos da pasta. Caso prefira, poderá salvá-los em seu Google Drive, criando uma cópia. Esses são os dados que serão utilizados no modelo (\"X\" e \"Y\" são os dados prontos e são suficientes caso deseje ir diretamente para o treinamento, pulando a etapa \"Preparação final dos Dados\". \"imgs\" e \"masks\" são os dados pré-processados, mas ainda não passados pela última etapa).\n",
        "\n",
        "Caso tenha baixado localmente:\n",
        "5. Aguarde o download dos arquivos. Após, no menu lateral esquerdo do colab clique no ícone de pasta (último ícone), e depois no primeiro ícone para upload de arquivos (\"Fazer upload para o armazenamento da sessão\").\n",
        "6. Adicione os dois arquivos previamente baixados.\n",
        "\n",
        "Pronto! Já está tudo preparado para execução.\n",
        "\n",
        "<strong>OBS: Caso deseje alterar de CPU para GPU, ou vice-versa, durante a execução, a sessão será reiniciada e tudo deverá ser executado novamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lVJEdXBiQpHl"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import Input\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical, Sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Conv2DTranspose, concatenate, Dropout, UpSampling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by14Yt1KXHQf",
        "outputId": "c0b75f53-12cc-4e8a-977e-42de15950b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pFrREWv8j2_"
      },
      "source": [
        "## Leitura dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xcp8wWyqVNBl"
      },
      "outputs": [],
      "source": [
        "file_x = open('/content/drive/MyDrive/Satelite Data/loaded_df/X.pkl', 'rb')\n",
        "\n",
        "X = pickle.load(file_x)\n",
        "\n",
        "file_y = open('/content/drive/MyDrive/Satelite Data/loaded_df/Y.pkl', 'rb')\n",
        "\n",
        "Y = pickle.load(file_y)\n",
        "\n",
        "file_x.close()\n",
        "file_y.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JH_u4yOh46M"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "O modelo deve ser rodado utlizando a A100 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDeZYCJ_WRnd",
        "outputId": "63a76a35-14c3-4899-bb00-449269018500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2160, 208, 208, 4)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "batch_size = X.shape[0]\n",
        "\n",
        "new_channel = np.ones((batch_size, 208, 208, 1))\n",
        "\n",
        "new_X = np.concatenate((X, new_channel), axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_m7hbDQdY8r4"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import UpSampling2D, Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O4jpVf7RXruB"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\n",
        "### TRANSFER LEARNING\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Models/Unet3.h5\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "input_layer = Input(shape=(208, 208, 4))\n",
        "\n",
        "outputs = {model.layers[0].name: input_layer}\n",
        "\n",
        "for layer in model.layers[1:]:\n",
        "    if 'concat' in layer.name:  \n",
        "        concat_inputs = [outputs[l.name] for l in layer._inbound_nodes[0].inbound_layers]\n",
        "        x = layer(concat_inputs)\n",
        "    else:\n",
        "        prev_layers = layer._inbound_nodes[0].inbound_layers\n",
        "        if isinstance(prev_layers, list):\n",
        "            layer_inputs = [outputs[l.name] for l in prev_layers]\n",
        "            x = layer(layer_inputs[0] if len(layer_inputs) == 1 else layer_inputs)\n",
        "        else:\n",
        "            x = layer(outputs[prev_layers.name])\n",
        "\n",
        "    outputs[layer.name] = x\n",
        "\n",
        "new_model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiHmDOMHYG_T"
      },
      "outputs": [],
      "source": [
        "new_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOY86r4fZLW5",
        "outputId": "5d346d40-96a7-4772-d05b-a74365dfcafa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de parâmetros no modelo é de 1,302,402.\n",
            "Total de parâmetros que podem ser treinados no modelo são 1,298,434.\n"
          ]
        }
      ],
      "source": [
        "total_params = new_model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in new_model.trainable_weights])\n",
        "\n",
        "print(f\"Total de parâmetros no modelo é de {total_params:,}.\")\n",
        "print(f\"Total de parâmetros que podem ser treinados no modelo são {num_trainable_params:,}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNFAoD0pZNSD",
        "outputId": "19683931-cb16-42fe-af5b-886d3fe8bd96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output tensor dimension for node 0: (None, 104, 104, 96)\n"
          ]
        }
      ],
      "source": [
        "last_desired_layer = model.get_layer('batch_normalization_21')\n",
        "last_output = last_desired_layer.get_output_at(1)\n",
        "print(\"Output tensor dimension for node 0:\", last_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FMeCbkQLZPaV"
      },
      "outputs": [],
      "source": [
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dropout(0.3)(last_output) \n",
        "\n",
        "x = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal', name=\"conv2d_19\")(x)\n",
        "x = layers.Conv2D(2, 1, padding='same', name=\"conv2d_20\")(x)\n",
        "x = UpSampling2D(size=(2, 2))(x)\n",
        "x = layers.Activation('softmax', name='softmax_activation')(x)\n",
        "cut_model = Model(new_model.input, x)\n",
        "cut_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tstZBD1hZRAF"
      },
      "outputs": [],
      "source": [
        "cut_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulo5glmqiZif",
        "outputId": "52a79731-3c1d-4cb6-e872-59ab7bd397e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de parâmetros no modelo é de 1,070,530.\n",
            "Total de parâmetros que podem ser treinados no modelo são 1,067,138.\n"
          ]
        }
      ],
      "source": [
        "total_params = cut_model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in cut_model.trainable_weights])\n",
        "\n",
        "print(f\"Total de parâmetros no modelo é de {total_params:,}.\")\n",
        "print(f\"Total de parâmetros que podem ser treinados no modelo são {num_trainable_params:,}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Iwwpyg5BcXRv"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_X, Y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShKF9ViuZg94"
      },
      "outputs": [],
      "source": [
        "results = cut_model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSUFY-vkebsN"
      },
      "outputs": [],
      "source": [
        "def plot_results(results):\n",
        "  acc = results.history['accuracy']\n",
        "  val_acc = results.history['val_accuracy']\n",
        "  loss = results.history['loss']\n",
        "  val_loss = results.history['val_loss']\n",
        "  epochs = range(len(acc))\n",
        "  plt.plot(epochs, acc, 'g', label='Precisão do conjunto de Treino')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Precisão do conjunto de Validação')\n",
        "  plt.plot(epochs, loss, 'r', label='Perda do conjunto de Treino')\n",
        "  plt.plot(epochs, val_loss, 'm', label='Perda do conjunto de Validação')\n",
        "  plt.title('Precisão dos conjuntos de Treino e Validação')\n",
        "  plt.xlabel('Épocas')\n",
        "  plt.ylabel('Precisão/Perda')\n",
        "  plt.legend(loc=0)\n",
        "  plt.figure()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_results(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U2ifyiubgkfu"
      },
      "outputs": [],
      "source": [
        "def VisualizeResults(index):\n",
        "    img = new_X[index]\n",
        "    img = img[np.newaxis, ...]\n",
        "    pred_y = cut_model.predict(img)\n",
        "    pred_mask = tf.argmax(pred_y[0], axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    fig, arr = plt.subplots(1, 3, figsize=(15, 15))\n",
        "    arr[0].imshow(new_X[index])\n",
        "    arr[0].set_title('Imagem Original')\n",
        "    arr[1].imshow(Y[index,:,:,0])\n",
        "    arr[1].set_title('Máscara Verdadeira')\n",
        "    arr[2].imshow(pred_mask[:,:,0])\n",
        "    arr[2].set_title('Máscara Predita')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-gv7__DhLSg"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(0, len(new_X))\n",
        "VisualizeResults(index)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uW9qi-hr70tv",
        "3H925fesE1lk",
        "z5NVNwVYFEv1",
        "D6hVwhybA_oP"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
